{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agentic Retrieval-Augmented Generation (RAG) with Local Llama 2 & ChromaDB\n",
    "\n",
    "## Overview\n",
    "This notebook implements an **Agentic Retrieval-Augmented Generation (RAG) pipeline**. It focuses on transcribing audio data, potentially from an Omi streaming device, storing both the transcription and audio, and then using the transcription with a local **Ai Studio** model and **ChromaDB** for intelligent question-answering. The system determines whether additional context is needed before generating responses.\n",
    "\n",
    "### Key Features:\n",
    "- **Audio Transcription Workflow** for processing data from devices like Omi.\n",
    "- **Storage of Audio and Transcriptions** for AI processing.\n",
    "- **Llama 2 Model** for high-quality text generation.\n",
    "- **ChromaDB Vector Store** for efficient semantic search on transcriptions.\n",
    "- **Dynamic Context Retrieval** to improve answer accuracy.\n",
    "- **Two Answering Modes**:\n",
    "  - With RAG (Retrieves relevant document content before responding).\n",
    "  - Without RAG (Directly generates responses)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pypdf==5.3.0 (from -r requirements.txt (line 3))\n",
      "  Downloading pypdf-5.3.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: torch in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 4)) (2.6.0+cpu)\n",
      "Collecting huggingface-hub (from -r requirements.txt (line 5))\n",
      "  Downloading huggingface_hub-0.31.4-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting langchain_community (from -r requirements.txt (line 6))\n",
      "  Downloading langchain_community-0.3.24-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting sentence_transformers (from -r requirements.txt (line 7))\n",
      "  Downloading sentence_transformers-4.1.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting chromadb (from -r requirements.txt (line 8))\n",
      "  Downloading chromadb-1.0.9-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: Plotly in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 9)) (6.0.1)\n",
      "Collecting scikit-image (from -r requirements.txt (line 10))\n",
      "  Downloading scikit_image-0.25.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: Seaborn in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 11)) (0.13.2)\n",
      "Collecting Altair (from -r requirements.txt (line 12))\n",
      "  Downloading altair-5.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting Bokeh (from -r requirements.txt (line 13))\n",
      "  Downloading bokeh-3.7.3-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting Bottleneck (from -r requirements.txt (line 14))\n",
      "  Downloading bottleneck-1.5.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
      "Collecting Bill (from -r requirements.txt (line 15))\n",
      "  Downloading bill-0.0.1.tar.gz (1.4 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting h5py (from -r requirements.txt (line 16))\n",
      "  Downloading h5py-3.13.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
      "Collecting Ipympl (from -r requirements.txt (line 17))\n",
      "  Downloading ipympl-0.9.7-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting Numba (from -r requirements.txt (line 18))\n",
      "  Downloading numba-0.61.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)\n",
      "Collecting Statsmodels (from -r requirements.txt (line 19))\n",
      "  Downloading statsmodels-0.14.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.2 kB)\n",
      "Collecting mlflow (from -r requirements.txt (line 20))\n",
      "  Downloading mlflow-2.22.0-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting llama-cpp-python (from -r requirements.txt (line 21))\n",
      "  Downloading llama_cpp_python-0.3.9.tar.gz (67.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.9/67.9 MB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting librosa (from -r requirements.txt (line 22))\n",
      "  Downloading librosa-0.11.0-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting espeakng (from -r requirements.txt (line 23))\n",
      "  Downloading espeakng-1.0.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.12/site-packages (from torch->-r requirements.txt (line 4)) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/codespace/.local/lib/python3.12/site-packages (from torch->-r requirements.txt (line 4)) (4.12.2)\n",
      "Requirement already satisfied: networkx in /home/codespace/.local/lib/python3.12/site-packages (from torch->-r requirements.txt (line 4)) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.12/site-packages (from torch->-r requirements.txt (line 4)) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/codespace/.local/lib/python3.12/site-packages (from torch->-r requirements.txt (line 4)) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in /home/codespace/.local/lib/python3.12/site-packages (from torch->-r requirements.txt (line 4)) (76.0.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/codespace/.local/lib/python3.12/site-packages (from torch->-r requirements.txt (line 4)) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from sympy==1.13.1->torch->-r requirements.txt (line 4)) (1.3.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub->-r requirements.txt (line 5)) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub->-r requirements.txt (line 5)) (6.0.2)\n",
      "Requirement already satisfied: requests in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub->-r requirements.txt (line 5)) (2.32.3)\n",
      "Collecting tqdm>=4.42.1 (from huggingface-hub->-r requirements.txt (line 5))\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.59 (from langchain_community->-r requirements.txt (line 6))\n",
      "  Downloading langchain_core-0.3.60-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting langchain<1.0.0,>=0.3.25 (from langchain_community->-r requirements.txt (line 6))\n",
      "  Downloading langchain-0.3.25-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain_community->-r requirements.txt (line 6))\n",
      "  Downloading sqlalchemy-2.0.41-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain_community->-r requirements.txt (line 6))\n",
      "  Downloading aiohttp-3.11.18-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting tenacity!=8.4.0,<10,>=8.1.0 (from langchain_community->-r requirements.txt (line 6))\n",
      "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community->-r requirements.txt (line 6))\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community->-r requirements.txt (line 6))\n",
      "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting langsmith<0.4,>=0.1.125 (from langchain_community->-r requirements.txt (line 6))\n",
      "  Downloading langsmith-0.3.42-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community->-r requirements.txt (line 6))\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /home/codespace/.local/lib/python3.12/site-packages (from langchain_community->-r requirements.txt (line 6)) (2.2.4)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence_transformers->-r requirements.txt (line 7))\n",
      "  Downloading transformers-4.52.1-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: scikit-learn in /home/codespace/.local/lib/python3.12/site-packages (from sentence_transformers->-r requirements.txt (line 7)) (1.6.1)\n",
      "Requirement already satisfied: scipy in /home/codespace/.local/lib/python3.12/site-packages (from sentence_transformers->-r requirements.txt (line 7)) (1.15.2)\n",
      "Requirement already satisfied: Pillow in /home/codespace/.local/lib/python3.12/site-packages (from sentence_transformers->-r requirements.txt (line 7)) (11.1.0)\n",
      "Collecting build>=1.0.3 (from chromadb->-r requirements.txt (line 8))\n",
      "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting pydantic>=1.9 (from chromadb->-r requirements.txt (line 8))\n",
      "  Downloading pydantic-2.11.4-py3-none-any.whl.metadata (66 kB)\n",
      "Collecting fastapi==0.115.9 (from chromadb->-r requirements.txt (line 8))\n",
      "  Downloading fastapi-0.115.9-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 8))\n",
      "  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting posthog>=2.4.0 (from chromadb->-r requirements.txt (line 8))\n",
      "  Downloading posthog-4.0.1-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb->-r requirements.txt (line 8))\n",
      "  Downloading onnxruntime-1.22.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb->-r requirements.txt (line 8))\n",
      "  Downloading opentelemetry_api-1.33.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb->-r requirements.txt (line 8))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.33.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb->-r requirements.txt (line 8))\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.54b1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb->-r requirements.txt (line 8))\n",
      "  Downloading opentelemetry_sdk-1.33.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting tokenizers>=0.13.2 (from chromadb->-r requirements.txt (line 8))\n",
      "  Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting pypika>=0.48.9 (from chromadb->-r requirements.txt (line 8))\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: overrides>=7.3.1 in /home/codespace/.local/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 8)) (7.7.0)\n",
      "Collecting importlib-resources (from chromadb->-r requirements.txt (line 8))\n",
      "  Downloading importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting grpcio>=1.58.0 (from chromadb->-r requirements.txt (line 8))\n",
      "  Downloading grpcio-1.71.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb->-r requirements.txt (line 8))\n",
      "  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (10 kB)\n",
      "Collecting typer>=0.9.0 (from chromadb->-r requirements.txt (line 8))\n",
      "  Downloading typer-0.15.4-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb->-r requirements.txt (line 8))\n",
      "  Downloading kubernetes-32.0.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting mmh3>=4.0.1 (from chromadb->-r requirements.txt (line 8))\n",
      "  Downloading mmh3-5.1.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
      "Collecting orjson>=3.9.12 (from chromadb->-r requirements.txt (line 8))\n",
      "  Downloading orjson-3.10.18-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /home/codespace/.local/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 8)) (0.28.1)\n",
      "Collecting rich>=10.11.0 (from chromadb->-r requirements.txt (line 8))\n",
      "  Downloading rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in /home/codespace/.local/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 8)) (4.23.0)\n",
      "Collecting starlette<0.46.0,>=0.40.0 (from fastapi==0.115.9->chromadb->-r requirements.txt (line 8))\n",
      "  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in /home/codespace/.local/lib/python3.12/site-packages (from Plotly->-r requirements.txt (line 9)) (1.31.0)\n",
      "Collecting imageio!=2.35.0,>=2.33 (from scikit-image->-r requirements.txt (line 10))\n",
      "  Downloading imageio-2.37.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting tifffile>=2022.8.12 (from scikit-image->-r requirements.txt (line 10))\n",
      "  Downloading tifffile-2025.5.10-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting lazy-loader>=0.4 (from scikit-image->-r requirements.txt (line 10))\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: pandas>=1.2 in /home/codespace/.local/lib/python3.12/site-packages (from Seaborn->-r requirements.txt (line 11)) (2.2.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /home/codespace/.local/lib/python3.12/site-packages (from Seaborn->-r requirements.txt (line 11)) (3.10.1)\n",
      "Requirement already satisfied: contourpy>=1.2 in /home/codespace/.local/lib/python3.12/site-packages (from Bokeh->-r requirements.txt (line 13)) (1.3.1)\n",
      "Requirement already satisfied: tornado>=6.2 in /home/codespace/.local/lib/python3.12/site-packages (from Bokeh->-r requirements.txt (line 13)) (6.4.2)\n",
      "Collecting xyzservices>=2021.09.1 (from Bokeh->-r requirements.txt (line 13))\n",
      "  Downloading xyzservices-2025.4.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: ipython<10 in /home/codespace/.local/lib/python3.12/site-packages (from Ipympl->-r requirements.txt (line 17)) (9.0.2)\n",
      "Collecting ipywidgets<9,>=7.6.0 (from Ipympl->-r requirements.txt (line 17))\n",
      "  Downloading ipywidgets-8.1.7-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: traitlets<6 in /home/codespace/.local/lib/python3.12/site-packages (from Ipympl->-r requirements.txt (line 17)) (5.14.3)\n",
      "Collecting llvmlite<0.45,>=0.44.0dev0 (from Numba->-r requirements.txt (line 18))\n",
      "  Downloading llvmlite-0.44.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting patsy>=0.5.6 (from Statsmodels->-r requirements.txt (line 19))\n",
      "  Downloading patsy-1.0.1-py2.py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting mlflow-skinny==2.22.0 (from mlflow->-r requirements.txt (line 20))\n",
      "  Downloading mlflow_skinny-2.22.0-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting Flask<4 (from mlflow->-r requirements.txt (line 20))\n",
      "  Downloading flask-3.1.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting alembic!=1.10.0,<2 (from mlflow->-r requirements.txt (line 20))\n",
      "  Downloading alembic-1.15.2-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting docker<8,>=4.0.0 (from mlflow->-r requirements.txt (line 20))\n",
      "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting graphene<4 (from mlflow->-r requirements.txt (line 20))\n",
      "  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting gunicorn<24 (from mlflow->-r requirements.txt (line 20))\n",
      "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting markdown<4,>=3.3 (from mlflow->-r requirements.txt (line 20))\n",
      "  Downloading markdown-3.8-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting pyarrow<20,>=4.0.0 (from mlflow->-r requirements.txt (line 20))\n",
      "  Downloading pyarrow-19.0.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting cachetools<6,>=5.0.0 (from mlflow-skinny==2.22.0->mlflow->-r requirements.txt (line 20))\n",
      "  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting click<9,>=7.0 (from mlflow-skinny==2.22.0->mlflow->-r requirements.txt (line 20))\n",
      "  Downloading click-8.2.0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting cloudpickle<4 (from mlflow-skinny==2.22.0->mlflow->-r requirements.txt (line 20))\n",
      "  Downloading cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==2.22.0->mlflow->-r requirements.txt (line 20))\n",
      "  Downloading databricks_sdk-0.53.0-py3-none-any.whl.metadata (39 kB)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in /home/codespace/.local/lib/python3.12/site-packages (from mlflow-skinny==2.22.0->mlflow->-r requirements.txt (line 20)) (3.1.44)\n",
      "Collecting importlib_metadata!=4.7.0,<9,>=3.7.0 (from mlflow-skinny==2.22.0->mlflow->-r requirements.txt (line 20))\n",
      "  Downloading importlib_metadata-8.7.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting protobuf<7,>=3.12.0 (from mlflow-skinny==2.22.0->mlflow->-r requirements.txt (line 20))\n",
      "  Downloading protobuf-6.31.0-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Collecting sqlparse<1,>=0.4.0 (from mlflow-skinny==2.22.0->mlflow->-r requirements.txt (line 20))\n",
      "  Downloading sqlparse-0.5.3-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting diskcache>=5.6.1 (from llama-cpp-python->-r requirements.txt (line 21))\n",
      "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting audioread>=2.1.9 (from librosa->-r requirements.txt (line 22))\n",
      "  Downloading audioread-3.0.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: joblib>=1.0 in /home/codespace/.local/lib/python3.12/site-packages (from librosa->-r requirements.txt (line 22)) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /home/codespace/.local/lib/python3.12/site-packages (from librosa->-r requirements.txt (line 22)) (5.2.1)\n",
      "Collecting soundfile>=0.12.1 (from librosa->-r requirements.txt (line 22))\n",
      "  Downloading soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl.metadata (16 kB)\n",
      "Collecting pooch>=1.1 (from librosa->-r requirements.txt (line 22))\n",
      "  Downloading pooch-1.8.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting soxr>=0.3.2 (from librosa->-r requirements.txt (line 22))\n",
      "  Downloading soxr-0.5.0.post1-cp312-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Collecting msgpack>=1.0 (from librosa->-r requirements.txt (line 22))\n",
      "  Downloading msgpack-1.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain_community->-r requirements.txt (line 6))\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain_community->-r requirements.txt (line 6))\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/codespace/.local/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community->-r requirements.txt (line 6)) (25.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain_community->-r requirements.txt (line 6))\n",
      "  Downloading frozenlist-1.6.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain_community->-r requirements.txt (line 6))\n",
      "  Downloading multidict-6.4.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain_community->-r requirements.txt (line 6))\n",
      "  Downloading propcache-0.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain_community->-r requirements.txt (line 6))\n",
      "  Downloading yarl-1.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (72 kB)\n",
      "Collecting Mako (from alembic!=1.10.0,<2->mlflow->-r requirements.txt (line 20))\n",
      "  Downloading mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb->-r requirements.txt (line 8))\n",
      "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community->-r requirements.txt (line 6))\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community->-r requirements.txt (line 6))\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /home/codespace/.local/lib/python3.12/site-packages (from docker<8,>=4.0.0->mlflow->-r requirements.txt (line 20)) (2.3.0)\n",
      "Collecting blinker>=1.9.0 (from Flask<4->mlflow->-r requirements.txt (line 20))\n",
      "  Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting itsdangerous>=2.2.0 (from Flask<4->mlflow->-r requirements.txt (line 20))\n",
      "  Downloading itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in /home/codespace/.local/lib/python3.12/site-packages (from Flask<4->mlflow->-r requirements.txt (line 20)) (3.0.2)\n",
      "Collecting werkzeug>=3.1.0 (from Flask<4->mlflow->-r requirements.txt (line 20))\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow->-r requirements.txt (line 20))\n",
      "  Downloading graphql_core-3.2.6-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow->-r requirements.txt (line 20))\n",
      "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7.0 in /home/codespace/.local/lib/python3.12/site-packages (from graphene<4->mlflow->-r requirements.txt (line 20)) (2.9.0.post0)\n",
      "Requirement already satisfied: anyio in /home/codespace/.local/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb->-r requirements.txt (line 8)) (4.9.0)\n",
      "Requirement already satisfied: certifi in /home/codespace/.local/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb->-r requirements.txt (line 8)) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /home/codespace/.local/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb->-r requirements.txt (line 8)) (1.0.7)\n",
      "Requirement already satisfied: idna in /home/codespace/.local/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb->-r requirements.txt (line 8)) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/codespace/.local/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb->-r requirements.txt (line 8)) (0.14.0)\n",
      "Requirement already satisfied: ipython-pygments-lexers in /home/codespace/.local/lib/python3.12/site-packages (from ipython<10->Ipympl->-r requirements.txt (line 17)) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/codespace/.local/lib/python3.12/site-packages (from ipython<10->Ipympl->-r requirements.txt (line 17)) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /home/codespace/.local/lib/python3.12/site-packages (from ipython<10->Ipympl->-r requirements.txt (line 17)) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/codespace/.local/lib/python3.12/site-packages (from ipython<10->Ipympl->-r requirements.txt (line 17)) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /home/codespace/.local/lib/python3.12/site-packages (from ipython<10->Ipympl->-r requirements.txt (line 17)) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/codespace/.local/lib/python3.12/site-packages (from ipython<10->Ipympl->-r requirements.txt (line 17)) (2.19.1)\n",
      "Requirement already satisfied: stack_data in /home/codespace/.local/lib/python3.12/site-packages (from ipython<10->Ipympl->-r requirements.txt (line 17)) (0.6.3)\n",
      "Requirement already satisfied: comm>=0.1.3 in /home/codespace/.local/lib/python3.12/site-packages (from ipywidgets<9,>=7.6.0->Ipympl->-r requirements.txt (line 17)) (0.2.2)\n",
      "Collecting widgetsnbextension~=4.0.14 (from ipywidgets<9,>=7.6.0->Ipympl->-r requirements.txt (line 17))\n",
      "  Downloading widgetsnbextension-4.0.14-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab_widgets~=3.0.15 (from ipywidgets<9,>=7.6.0->Ipympl->-r requirements.txt (line 17))\n",
      "  Downloading jupyterlab_widgets-3.0.15-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/codespace/.local/lib/python3.12/site-packages (from jsonschema>=4.19.0->chromadb->-r requirements.txt (line 8)) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/codespace/.local/lib/python3.12/site-packages (from jsonschema>=4.19.0->chromadb->-r requirements.txt (line 8)) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/codespace/.local/lib/python3.12/site-packages (from jsonschema>=4.19.0->chromadb->-r requirements.txt (line 8)) (0.23.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/codespace/.local/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 8)) (1.17.0)\n",
      "Collecting google-auth>=1.0.1 (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 8))\n",
      "  Downloading google_auth-2.40.1-py2.py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /home/codespace/.local/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 8)) (1.8.0)\n",
      "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 8))\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting oauthlib>=3.2.2 (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 8))\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 8))\n",
      "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain<1.0.0,>=0.3.25->langchain_community->-r requirements.txt (line 6))\n",
      "  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<1.0.0,>=0.3.59->langchain_community->-r requirements.txt (line 6))\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.4,>=0.1.125->langchain_community->-r requirements.txt (line 6))\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith<0.4,>=0.1.125->langchain_community->-r requirements.txt (line 6))\n",
      "  Downloading zstandard-0.23.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->Seaborn->-r requirements.txt (line 11)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->Seaborn->-r requirements.txt (line 11)) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->Seaborn->-r requirements.txt (line 11)) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->Seaborn->-r requirements.txt (line 11)) (3.2.1)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 8))\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 8))\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb->-r requirements.txt (line 8))\n",
      "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting importlib_metadata!=4.7.0,<9,>=3.7.0 (from mlflow-skinny==2.22.0->mlflow->-r requirements.txt (line 20))\n",
      "  Downloading importlib_metadata-8.6.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 8))\n",
      "  Downloading googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.33.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 8))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.33.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-proto==1.33.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 8))\n",
      "  Downloading opentelemetry_proto-1.33.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting protobuf<7,>=3.12.0 (from mlflow-skinny==2.22.0->mlflow->-r requirements.txt (line 20))\n",
      "  Downloading protobuf-5.29.4-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.54b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 8))\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.54b1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-instrumentation==0.54b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 8))\n",
      "  Downloading opentelemetry_instrumentation-0.54b1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.54b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 8))\n",
      "  Downloading opentelemetry_semantic_conventions-0.54b1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-util-http==0.54b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 8))\n",
      "  Downloading opentelemetry_util_http-0.54b1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting wrapt<2.0.0,>=1.0.0 (from opentelemetry-instrumentation==0.54b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 8))\n",
      "  Downloading wrapt-1.17.2-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.54b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 8))\n",
      "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.12/site-packages (from pandas>=1.2->Seaborn->-r requirements.txt (line 11)) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.12/site-packages (from pandas>=1.2->Seaborn->-r requirements.txt (line 11)) (2025.1)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /home/codespace/.local/lib/python3.12/site-packages (from pooch>=1.1->librosa->-r requirements.txt (line 22)) (4.3.6)\n",
      "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb->-r requirements.txt (line 8))\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting distro>=1.5.0 (from posthog>=2.4.0->chromadb->-r requirements.txt (line 8))\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=1.9->chromadb->-r requirements.txt (line 8))\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic>=1.9->chromadb->-r requirements.txt (line 8))\n",
      "  Downloading pydantic_core-2.33.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic>=1.9->chromadb->-r requirements.txt (line 8))\n",
      "  Downloading typing_inspection-0.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community->-r requirements.txt (line 6))\n",
      "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests->huggingface-hub->-r requirements.txt (line 5)) (3.4.1)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->chromadb->-r requirements.txt (line 8))\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from scikit-learn->sentence_transformers->-r requirements.txt (line 7)) (3.6.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /home/codespace/.local/lib/python3.12/site-packages (from soundfile>=0.12.1->librosa->-r requirements.txt (line 22)) (1.17.1)\n",
      "Collecting greenlet>=1 (from SQLAlchemy<3,>=1.4->langchain_community->-r requirements.txt (line 6))\n",
      "  Downloading greenlet-3.2.2-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers<5.0.0,>=4.41.0->sentence_transformers->-r requirements.txt (line 7))\n",
      "  Downloading regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers<5.0.0,>=4.41.0->sentence_transformers->-r requirements.txt (line 7))\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting click<9,>=7.0 (from mlflow-skinny==2.22.0->mlflow->-r requirements.txt (line 20))\n",
      "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer>=0.9.0->chromadb->-r requirements.txt (line 8))\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 8))\n",
      "  Downloading httptools-0.6.4-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 8))\n",
      "  Downloading uvloop-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 8))\n",
      "  Downloading watchfiles-1.0.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 8))\n",
      "  Downloading websockets-15.0.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: pycparser in /home/codespace/.local/lib/python3.12/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa->-r requirements.txt (line 22)) (2.22)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/codespace/.local/lib/python3.12/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.22.0->mlflow->-r requirements.txt (line 20)) (4.0.12)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 8))\n",
      "  Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 8))\n",
      "  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting zipp>=3.20 (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.22.0->mlflow->-r requirements.txt (line 20))\n",
      "  Downloading zipp-3.21.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /home/codespace/.local/lib/python3.12/site-packages (from jedi>=0.16->ipython<10->Ipympl->-r requirements.txt (line 17)) (0.8.4)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/codespace/.local/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.59->langchain_community->-r requirements.txt (line 6)) (3.0.0)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb->-r requirements.txt (line 8))\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/codespace/.local/lib/python3.12/site-packages (from pexpect>4.3->ipython<10->Ipympl->-r requirements.txt (line 17)) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/codespace/.local/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython<10->Ipympl->-r requirements.txt (line 17)) (0.2.13)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/codespace/.local/lib/python3.12/site-packages (from anyio->httpx>=0.27.0->chromadb->-r requirements.txt (line 8)) (1.3.1)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community->-r requirements.txt (line 6))\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 8))\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/codespace/.local/lib/python3.12/site-packages (from stack_data->ipython<10->Ipympl->-r requirements.txt (line 17)) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from stack_data->ipython<10->Ipympl->-r requirements.txt (line 17)) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /home/codespace/.local/lib/python3.12/site-packages (from stack_data->ipython<10->Ipympl->-r requirements.txt (line 17)) (0.2.3)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/codespace/.local/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.22.0->mlflow->-r requirements.txt (line 20)) (5.0.2)\n",
      "Collecting pyasn1<0.7.0,>=0.6.1 (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 8))\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Downloading pypdf-5.3.0-py3-none-any.whl (300 kB)\n",
      "Downloading huggingface_hub-0.31.4-py3-none-any.whl (489 kB)\n",
      "Downloading langchain_community-0.3.24-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sentence_transformers-4.1.0-py3-none-any.whl (345 kB)\n",
      "Downloading chromadb-1.0.9-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.9/18.9 MB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading fastapi-0.115.9-py3-none-any.whl (94 kB)\n",
      "Downloading scikit_image-0.25.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.0/15.0 MB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading altair-5.5.0-py3-none-any.whl (731 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.2/731.2 kB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading bokeh-3.7.3-py3-none-any.whl (7.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading bottleneck-1.5.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (362 kB)\n",
      "Downloading h5py-3.13.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ipympl-0.9.7-py3-none-any.whl (515 kB)\n",
      "Downloading numba-0.61.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading statsmodels-0.14.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mlflow-2.22.0-py3-none-any.whl (29.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.0/29.0 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading mlflow_skinny-2.22.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading librosa-0.11.0-py3-none-any.whl (260 kB)\n",
      "Downloading espeakng-1.0.3-py3-none-any.whl (16 kB)\n",
      "Downloading aiohttp-3.11.18-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading alembic-1.15.2-py3-none-any.whl (231 kB)\n",
      "Downloading audioread-3.0.1-py3-none-any.whl (23 kB)\n",
      "Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_28_x86_64.whl (284 kB)\n",
      "Downloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "Downloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
      "Downloading flask-3.1.1-py3-none-any.whl (103 kB)\n",
      "Downloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
      "Downloading grpcio-1.71.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
      "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading imageio-2.37.0-py3-none-any.whl (315 kB)\n",
      "Downloading ipywidgets-8.1.7-py3-none-any.whl (139 kB)\n",
      "Downloading kubernetes-32.0.1-py2.py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain-0.3.25-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.3.60-py3-none-any.whl (437 kB)\n",
      "Downloading langsmith-0.3.42-py3-none-any.whl (360 kB)\n",
      "Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Downloading llvmlite-0.44.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading markdown-3.8-py3-none-any.whl (106 kB)\n",
      "Downloading mmh3-5.1.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (101 kB)\n",
      "Downloading msgpack-1.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (401 kB)\n",
      "Downloading onnxruntime-1.22.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_api-1.33.1-py3-none-any.whl (65 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_grpc-1.33.1-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.33.1-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_proto-1.33.1-py3-none-any.whl (55 kB)\n",
      "Downloading opentelemetry_instrumentation_fastapi-0.54b1-py3-none-any.whl (12 kB)\n",
      "Downloading opentelemetry_instrumentation-0.54b1-py3-none-any.whl (31 kB)\n",
      "Downloading opentelemetry_instrumentation_asgi-0.54b1-py3-none-any.whl (16 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.54b1-py3-none-any.whl (194 kB)\n",
      "Downloading opentelemetry_util_http-0.54b1-py3-none-any.whl (7.3 kB)\n",
      "Downloading opentelemetry_sdk-1.33.1-py3-none-any.whl (118 kB)\n",
      "Downloading orjson-3.10.18-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (133 kB)\n",
      "Downloading patsy-1.0.1-py2.py3-none-any.whl (232 kB)\n",
      "Downloading pooch-1.8.2-py3-none-any.whl (64 kB)\n",
      "Downloading posthog-4.0.1-py2.py3-none-any.whl (92 kB)\n",
      "Downloading pyarrow-19.0.1-cp312-cp312-manylinux_2_28_x86_64.whl (42.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.11.4-py3-none-any.whl (443 kB)\n",
      "Downloading pydantic_core-2.33.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
      "Downloading rich-14.0.0-py3-none-any.whl (243 kB)\n",
      "Downloading soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading soxr-0.5.0.post1-cp312-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (248 kB)\n",
      "Downloading sqlalchemy-2.0.41-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Downloading tifffile-2025.5.10-py3-none-any.whl (226 kB)\n",
      "Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading transformers-4.52.1-py3-none-any.whl (10.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typer-0.15.4-py3-none-any.whl (45 kB)\n",
      "Downloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
      "Downloading xyzservices-2025.4.0-py3-none-any.whl (90 kB)\n",
      "Downloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Downloading cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading databricks_sdk-0.53.0-py3-none-any.whl (700 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m700.2/700.2 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
      "Downloading frozenlist-1.6.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (316 kB)\n",
      "Downloading google_auth-2.40.1-py2.py3-none-any.whl (216 kB)\n",
      "Downloading googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
      "Downloading graphql_core-3.2.6-py3-none-any.whl (203 kB)\n",
      "Downloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
      "Downloading greenlet-3.2.2-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (603 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m603.9/603.9 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httptools-0.6.4-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (510 kB)\n",
      "Downloading importlib_metadata-8.6.1-py3-none-any.whl (26 kB)\n",
      "Downloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading jupyterlab_widgets-3.0.15-py3-none-any.whl (216 kB)\n",
      "Downloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading multidict-6.4.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (223 kB)\n",
      "Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Downloading propcache-0.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (245 kB)\n",
      "Downloading protobuf-5.29.4-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
      "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
      "Downloading regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (796 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m796.9/796.9 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading sqlparse-0.5.3-py3-none-any.whl (44 kB)\n",
      "Downloading starlette-0.45.3-py3-none-any.whl (71 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading typing_inspection-0.4.0-py3-none-any.whl (14 kB)\n",
      "Downloading uvloop-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading watchfiles-1.0.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (454 kB)\n",
      "Downloading websockets-15.0.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (182 kB)\n",
      "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading widgetsnbextension-4.0.14-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading yarl-1.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (349 kB)\n",
      "Downloading zstandard-0.23.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Downloading mako-1.3.10-py3-none-any.whl (78 kB)\n",
      "Downloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
      "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Downloading wrapt-1.17.2-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (89 kB)\n",
      "Downloading zipp-3.21.0-py3-none-any.whl (9.6 kB)\n",
      "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Building wheels for collected packages: Bill, llama-cpp-python, pypika\n",
      "  Building wheel for Bill (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for Bill: filename=bill-0.0.1-py3-none-any.whl size=1425 sha256=56adbc9ea35d9697d04dd8e9d0ddec2ee4d1eed61e4d7aa25c99a5c99c4d6117\n",
      "  Stored in directory: /home/codespace/.cache/pip/wheels/0d/2c/c3/e8d7bbbb166029a4fe2b9a11a56c71666ec22d99152f13fd94\n",
      "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.3.9-cp312-cp312-linux_x86_64.whl size=3980483 sha256=397e93853d90fa8b3d8a350d78d381084a08b7a1c17777df0489f0b230efd72d\n",
      "  Stored in directory: /home/codespace/.cache/pip/wheels/e9/22/42/98dca29f6195951fae2aa548582827a45306350e282ab30617\n",
      "  Building wheel for pypika (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53801 sha256=234b99e458a2c4ed6f0f7f3febfd2514d4d5fd6922142123b07fb27dfaa6a53a\n",
      "  Stored in directory: /home/codespace/.cache/pip/wheels/d5/3d/69/8d68d249cd3de2584f226e27fd431d6344f7d70fd856ebd01b\n",
      "Successfully built Bill llama-cpp-python pypika\n",
      "Installing collected packages: pypika, flatbuffers, durationpy, zstandard, zipp, xyzservices, wrapt, widgetsnbextension, werkzeug, websockets, uvloop, typing-inspection, tqdm, tifffile, tenacity, sqlparse, soxr, shellingham, safetensors, regex, python-dotenv, pyproject_hooks, pypdf, pydantic-core, pyasn1, pyarrow, protobuf, propcache, patsy, orjson, opentelemetry-util-http, oauthlib, mypy-extensions, multidict, msgpack, mmh3, mdurl, marshmallow, markdown, Mako, llvmlite, lazy-loader, jupyterlab_widgets, jsonpatch, itsdangerous, importlib-resources, imageio, humanfriendly, httpx-sse, httptools, h5py, gunicorn, grpcio, greenlet, graphql-core, frozenlist, espeakng, distro, diskcache, cloudpickle, click, cachetools, Bottleneck, blinker, Bill, bcrypt, backoff, audioread, asgiref, annotated-types, aiohappyeyeballs, yarl, watchfiles, uvicorn, typing-inspect, starlette, SQLAlchemy, soundfile, scikit-image, rsa, requests-toolbelt, requests-oauthlib, pydantic, pyasn1-modules, posthog, pooch, opentelemetry-proto, Numba, markdown-it-py, llama-cpp-python, importlib_metadata, huggingface-hub, graphql-relay, googleapis-common-protos, Flask, docker, deprecated, coloredlogs, build, aiosignal, tokenizers, Statsmodels, rich, pydantic-settings, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, onnxruntime, librosa, langsmith, ipywidgets, graphene, google-auth, fastapi, dataclasses-json, Bokeh, alembic, aiohttp, typer, transformers, opentelemetry-semantic-conventions, langchain-core, kubernetes, Ipympl, databricks-sdk, Altair, sentence_transformers, opentelemetry-sdk, opentelemetry-instrumentation, langchain-text-splitters, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, mlflow-skinny, langchain, opentelemetry-instrumentation-fastapi, mlflow, langchain_community, chromadb\n",
      "Successfully installed Altair-5.5.0 Bill-0.0.1 Bokeh-3.7.3 Bottleneck-1.5.0 Flask-3.1.1 Ipympl-0.9.7 Mako-1.3.10 Numba-0.61.2 SQLAlchemy-2.0.41 Statsmodels-0.14.4 aiohappyeyeballs-2.6.1 aiohttp-3.11.18 aiosignal-1.3.2 alembic-1.15.2 annotated-types-0.7.0 asgiref-3.8.1 audioread-3.0.1 backoff-2.2.1 bcrypt-4.3.0 blinker-1.9.0 build-1.2.2.post1 cachetools-5.5.2 chromadb-1.0.9 click-8.1.8 cloudpickle-3.1.1 coloredlogs-15.0.1 databricks-sdk-0.53.0 dataclasses-json-0.6.7 deprecated-1.2.18 diskcache-5.6.3 distro-1.9.0 docker-7.1.0 durationpy-0.10 espeakng-1.0.3 fastapi-0.115.9 flatbuffers-25.2.10 frozenlist-1.6.0 google-auth-2.40.1 googleapis-common-protos-1.70.0 graphene-3.4.3 graphql-core-3.2.6 graphql-relay-3.2.0 greenlet-3.2.2 grpcio-1.71.0 gunicorn-23.0.0 h5py-3.13.0 httptools-0.6.4 httpx-sse-0.4.0 huggingface-hub-0.31.4 humanfriendly-10.0 imageio-2.37.0 importlib-resources-6.5.2 importlib_metadata-8.6.1 ipywidgets-8.1.7 itsdangerous-2.2.0 jsonpatch-1.33 jupyterlab_widgets-3.0.15 kubernetes-32.0.1 langchain-0.3.25 langchain-core-0.3.60 langchain-text-splitters-0.3.8 langchain_community-0.3.24 langsmith-0.3.42 lazy-loader-0.4 librosa-0.11.0 llama-cpp-python-0.3.9 llvmlite-0.44.0 markdown-3.8 markdown-it-py-3.0.0 marshmallow-3.26.1 mdurl-0.1.2 mlflow-2.22.0 mlflow-skinny-2.22.0 mmh3-5.1.0 msgpack-1.1.0 multidict-6.4.4 mypy-extensions-1.1.0 oauthlib-3.2.2 onnxruntime-1.22.0 opentelemetry-api-1.33.1 opentelemetry-exporter-otlp-proto-common-1.33.1 opentelemetry-exporter-otlp-proto-grpc-1.33.1 opentelemetry-instrumentation-0.54b1 opentelemetry-instrumentation-asgi-0.54b1 opentelemetry-instrumentation-fastapi-0.54b1 opentelemetry-proto-1.33.1 opentelemetry-sdk-1.33.1 opentelemetry-semantic-conventions-0.54b1 opentelemetry-util-http-0.54b1 orjson-3.10.18 patsy-1.0.1 pooch-1.8.2 posthog-4.0.1 propcache-0.3.1 protobuf-5.29.4 pyarrow-19.0.1 pyasn1-0.6.1 pyasn1-modules-0.4.2 pydantic-2.11.4 pydantic-core-2.33.2 pydantic-settings-2.9.1 pypdf-5.3.0 pypika-0.48.9 pyproject_hooks-1.2.0 python-dotenv-1.1.0 regex-2024.11.6 requests-oauthlib-2.0.0 requests-toolbelt-1.0.0 rich-14.0.0 rsa-4.9.1 safetensors-0.5.3 scikit-image-0.25.2 sentence_transformers-4.1.0 shellingham-1.5.4 soundfile-0.13.1 soxr-0.5.0.post1 sqlparse-0.5.3 starlette-0.45.3 tenacity-9.1.2 tifffile-2025.5.10 tokenizers-0.21.1 tqdm-4.67.1 transformers-4.52.1 typer-0.15.4 typing-inspect-0.9.0 typing-inspection-0.4.0 uvicorn-0.34.2 uvloop-0.21.0 watchfiles-1.0.5 websockets-15.0.1 werkzeug-3.1.3 widgetsnbextension-4.0.14 wrapt-1.17.2 xyzservices-2025.4.0 yarl-1.20.0 zipp-3.21.0 zstandard-0.23.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install required packages if you have not installed them already\n",
    "!pip install -r requirements.txt --verbose --quiet\n",
    "!pip install -q --upgrade pip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔧 Step 1: Model Setup\n",
    "\n",
    "We will set up **Llama 2 (7B)** for text generation. If the model is not found locally, it will be downloaded from Hugging Face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model not found locally. Downloading Llama 2 model...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'hf_hub_download' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     16\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mModel not found locally. Downloading Llama 2 model...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     18\u001b[39m     \u001b[38;5;66;03m# Download the model\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     model_path = \u001b[43mhf_hub_download\u001b[49m(\n\u001b[32m     20\u001b[39m         repo_id=\u001b[33m\"\u001b[39m\u001b[33mTheBloke/Llama-2-7B-Chat-GGUF\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     21\u001b[39m         filename=MODEL_FILENAME,\n\u001b[32m     22\u001b[39m         local_dir=MODEL_DIR\n\u001b[32m     23\u001b[39m     )\n\u001b[32m     24\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel downloaded to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     26\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUsing model at: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'hf_hub_download' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "MODEL_FILENAME = \"llama-2-7b-chat.Q4_K_M.gguf\"\n",
    "MODEL_DIR = \"model\"\n",
    "EXPECTED_PATH = os.path.join(MODEL_DIR, MODEL_FILENAME)\n",
    "\n",
    "# Ensure model directory exists\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "# Check if model already exists\n",
    "if os.path.exists(EXPECTED_PATH):\n",
    "    print(f\"Model already exists at: {EXPECTED_PATH}\")\n",
    "    model_path = EXPECTED_PATH\n",
    "else:\n",
    "    print(\"Model not found locally. Downloading Llama 2 model...\")\n",
    "    \n",
    "    # Download the model\n",
    "    model_path = hf_hub_download(\n",
    "        repo_id=\"TheBloke/Llama-2-7B-Chat-GGUF\",\n",
    "        filename=MODEL_FILENAME,\n",
    "        local_dir=MODEL_DIR\n",
    "    )\n",
    "    print(f\"Model downloaded to: {model_path}\")\n",
    "\n",
    "print(f\"Using model at: {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model with the local path and GPU acceleration\n",
    "llm = LlamaCpp(\n",
    "    model_path=EXPECTED_PATH,\n",
    "    temperature=0.25,\n",
    "    max_tokens=2000,\n",
    "    n_ctx=4096,\n",
    "    top_p=1.0,\n",
    "    verbose=False,\n",
    "    n_gpu_layers=30,  # Utilize some available GPU layers\n",
    "    n_batch=512,      # Optimize batch size for parallel processing\n",
    "    f16_kv=True,      # Enable half-precision for key/value cache\n",
    "    use_mlock=True,   # Lock memory to prevent swapping\n",
    "    use_mmap=True     # Utilize memory mapping for faster loading\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📄 Step 2: Loading, Transcribing, and Storing Audio Data\n",
    "\n",
    "This step outlines the process for loading audio data (e.g., from an Omi streaming device), transcribing it, and preparing it for storage and further processing. Both the raw audio and its transcription are valuable assets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load the Audio File Document ---\n",
    "# --- Load the Audio File Document and Audio Collection System ---\n",
    "\n",
    "# Install whisper if not already installed\n",
    "%pip install -q openai-whisper\n",
    "\n",
    "import whisper\n",
    "import os\n",
    "\n",
    "# Define the Audio File file path\n",
    "AUDIO_PATH = \"./data/tester.mp3\"\n",
    "# Check if the file exists\n",
    "print(f\"Loading AUDIO from: {AUDIO_PATH}\")\n",
    "\n",
    "# Define the audio collection system\n",
    "AUDIO_COLLECTION_SYSTEM = \"MyAudioSystem\"\n",
    "\n",
    "# Load and transcribe the audio file using whisper\n",
    "model = whisper.load_model(\"base\")\n",
    "result = model.transcribe(AUDIO_PATH)\n",
    "text_content = result[\"text\"]\n",
    "\n",
    "# For compatibility with the rest of your code, wrap the text in a document-like object\n",
    "class AudioDocument:\n",
    "    def __init__(self, text):\n",
    "        self.text = text\n",
    "    def getPageText(self):\n",
    "        return self.text\n",
    "\n",
    "documents = [AudioDocument(text_content)]\n",
    "\n",
    "print(f\"Successfully loaded {len(documents)} document(s) from the AUDIO.\")\n",
    "# Initialize an empty list for the audio files\n",
    "audio_files = []\n",
    "\n",
    "# Iterate through each document\n",
    "for document in documents:\n",
    "    # Get the current page's text content\n",
    "    text_content = document.getPageText()\n",
    "\n",
    "    # Extract relevant information from the text, e.g., keywords or phrases\n",
    "    def extractRelevantInfo(text):\n",
    "        # Placeholder: just return the text itself\n",
    "        return text\n",
    "    extracted_info = extractRelevantInfo(text_content)\n",
    "\n",
    "    # Define a placeholder for createAudioFile\n",
    "    def createAudioFile(system, info):\n",
    "        # Placeholder: just return a tuple for demonstration\n",
    "        return (system, info)\n",
    "\n",
    "    # Create an audio file based on the extracted information\n",
    "    audio_file = createAudioFile(AUDIO_COLLECTION_SYSTEM, extracted_info)\n",
    "\n",
    "    # Add the audio file to the collection system's list\n",
    "    audio_files.append(audio_file)\n",
    "print(f\"Successfully loaded {len(documents)} document(s) from the AUDIO and created {len(audio_files)} audio file(s).\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Audio Event Detection (Sound Tagging) ---\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "# Download and load a pre-trained PANNs model for sound event detection\n",
    "panns_model = torch.hub.load('qiuqiangkong/panns_transfer_to_audio_tagging', 'Cnn14', pretrained=True)\n",
    "panns_model.eval()\n",
    "\n",
    "# Load and preprocess audio\n",
    "waveform, sr = torchaudio.load(AUDIO_PATH)\n",
    "if sr != 32000:\n",
    "    waveform = torchaudio.transforms.Resample(orig_freq=sr, new_freq=32000)(waveform)\n",
    "    sr = 32000\n",
    "\n",
    "# PANNs expects mono audio\n",
    "if waveform.shape[0] > 1:\n",
    "    waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
    "\n",
    "# Run model and get tags\n",
    "with torch.no_grad():\n",
    "    output = panns_model(waveform)\n",
    "    # Get top 3 predicted sound classes\n",
    "    labels = panns_model.labels\n",
    "    topk = torch.topk(output['clipwise_output'][0], 3)\n",
    "    sound_tags = [labels[i] for i in topk.indices.tolist()]\n",
    "\n",
    "print(\"Detected sound types:\", sound_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ✂️ Step 3: Chunking Audio Transcriptions for RAG\n",
    "\n",
    "The transcribed text from the audio data is split into **small overlapping chunks** (approximately **500 characters**). These chunks are then used for embedding and storage in ChromaDB to enable semantic search for the RAG pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Split the Audio Content into Manageable Chunks with Sound Tags ---\n",
    "\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "CHUNK_SIZE = 500\n",
    "CHUNK_OVERLAP = 50\n",
    "text_splitter = CharacterTextSplitter(chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP)\n",
    "\n",
    "# Split the transcription into chunks\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "# Attach sound tags to each chunk as metadata\n",
    "for doc in docs:\n",
    "    doc.page_content = f\"Transcription: {doc.page_content}\\nSound tags: {', '.join(sound_tags)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔍 Step 4: Initializing the Embedding Model\n",
    "\n",
    "To convert text into numerical representations for efficient similarity search, we use **all-MiniLM-L6-v2** from `sentence-transformers`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Initialize the Embedding Model ---\n",
    "\n",
    "# Define the embedding model name\n",
    "MODEL_NAME = \"all-MiniLM-L6-v2\"\n",
    "\n",
    "# Load the embedding model\n",
    "embedding_model = SentenceTransformer(MODEL_NAME)\n",
    "\n",
    "print(f\"Successfully loaded embedding model: {MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🧠 Step 5: Computing Embeddings for Document Chunks\n",
    "\n",
    "Each chunk is converted into a **vector representation** using our embedding model. This allows us to perform **semantic similarity searches** later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Compute Embeddings for Each Text Chunk ---\n",
    "\n",
    "# Extract text content from each chunk\n",
    "doc_texts = [doc.page_content for doc in docs]\n",
    "\n",
    "# Compute embeddings for the extracted text chunks\n",
    "document_embeddings = embedding_model.encode(doc_texts, convert_to_numpy=True)\n",
    "\n",
    "# Display the result\n",
    "print(\"Successfully computed embeddings for each text chunk.\")\n",
    "print(f\"Embeddings Shape: {document_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🗄️ Step 6: Storing Document Embeddings in ChromaDB\n",
    "\n",
    "We initialize **ChromaDB**, a high-performance **vector database**, and store our computed embeddings to enable efficient retrieval of relevant text chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Initialize and Populate the Chroma Vector Database ---\n",
    "\n",
    "# Define Chroma database path and collection name\n",
    "CHROMA_DB_PATH = \"./chroma_db\"\n",
    "COLLECTION_NAME = \"document_embeddings\"\n",
    "\n",
    "# Initialize Chroma client\n",
    "chroma_client = chromadb.PersistentClient(path=CHROMA_DB_PATH)\n",
    "collection = chroma_client.get_or_create_collection(name=COLLECTION_NAME)\n",
    "\n",
    "# Add document embeddings to the Chroma collection\n",
    "for i, embedding in enumerate(document_embeddings):\n",
    "    collection.add(\n",
    "        ids=[str(i)],  # Chroma requires string IDs\n",
    "        embeddings=[embedding.tolist()],\n",
    "        metadatas=[{\"text\": doc_texts[i]}]\n",
    "    )\n",
    "\n",
    "print(\"Successfully populated Chroma database with document embeddings.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔎 Step 7: Implementing Vector Search Tool\n",
    "\n",
    "To retrieve relevant text passages from the database, we define a **vector search function** that finds the most relevant chunks based on a user query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define the Vector Search Tool ---\n",
    "def vector_search_tool(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Searches the Chroma database for relevant text chunks based on the query.\n",
    "    Computes the query embedding, retrieves the top 5 most relevant text chunks,\n",
    "    and returns them as a formatted string.\n",
    "    \"\"\"\n",
    "    # Compute the query embedding\n",
    "    query_embedding = embedding_model.encode(query, convert_to_numpy=True).tolist()\n",
    "    \n",
    "    # Define the number of nearest neighbors to retrieve\n",
    "    TOP_K = 5\n",
    "    \n",
    "    # Perform the search in the Chroma database\n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_embedding],\n",
    "        n_results=TOP_K\n",
    "    )\n",
    "    \n",
    "    # Retrieve and format the corresponding text chunks\n",
    "    retrieved_chunks = [metadata[\"text\"] for metadata in results[\"metadatas\"][0]]\n",
    "    return \"\\n\\n\".join(retrieved_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🤖 Step 8: Context Need Assessment\n",
    "\n",
    "Instead of always retrieving context, we determine if the query **requires external document context** before generating a response. This creates an agentic workflow that makes autonomous decisions to complete the task at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define the Meta-Evaluation Function ---\n",
    "def needs_context(query: str) -> bool:\n",
    "    \"\"\"\n",
    "    Determines if additional context from an external document is required to generate an accurate and detailed answer.\n",
    "    Returns True if context is needed (response contains \"YES\"), False otherwise.\n",
    "\n",
    "    Args:\n",
    "        query (str): The user's query to evaluate.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if external context is required, False otherwise.\n",
    "    \"\"\"\n",
    "    meta_prompt = (\n",
    "        \"Based on the following query, decide if additional context from an external document is needed \"\n",
    "        \"to generate an accurate and detailed answer. Have a tendency to use an external document if the query is not a very familiar topic. If in doubt, assume context is required and answer 'YES'.\\n\"\n",
    "        \"Answer with a single word: YES if additional context from an external document would be helpful to answer the query, \"\n",
    "        \"or NO if not. Do not say anything other than YES or NO.\\n\"\n",
    "        f\"Query: {query}\\n\"\n",
    "        \"Answer:\"\n",
    "    )\n",
    "    meta_response = llm.invoke(meta_prompt)\n",
    "    print(\"Meta Response (is external document retrieval necessary?):\", meta_response)\n",
    "    return \"YES\" in meta_response.upper()\n",
    "\n",
    "\n",
    "# --- Define the Main Answer Generation Function with RAG (Retrieve and Generate) ---\n",
    "def generate_answer_with_agentic_rag(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Generates a detailed and accurate answer to the user's query by using context when needed.\n",
    "    If additional context is required, it is retrieved from the vector store and included in the prompt.\n",
    "    If not, the answer is generated using the query alone.\n",
    "\n",
    "    Args:\n",
    "        query (str): The user's query to answer.\n",
    "\n",
    "    Returns:\n",
    "        str: The generated answer based on the query.\n",
    "    \"\"\"\n",
    "    if needs_context(query):\n",
    "        # Retrieve additional context from the vector store\n",
    "        context = vector_search_tool(query)\n",
    "        \n",
    "        # Construct the enriched prompt with the additional context\n",
    "        enriched_prompt = (\n",
    "            \"Here is additional context from our document:\\n\"\n",
    "            f\"{context}\\n\\n\"\n",
    "            f\"Based on this context and the query: {query}\\n\"\n",
    "            \"Please provide a detailed and accurate answer.\\n\"\n",
    "            \"Answer:\"\n",
    "        )\n",
    "        final_response = llm.invoke(enriched_prompt)\n",
    "    else:\n",
    "        # Generate an answer using the original query directly\n",
    "        direct_prompt = (\n",
    "            \"Please provide a detailed and accurate answer to the following query:\\n\"\n",
    "            f\"{query}\\n\"\n",
    "            \"Answer:\"\n",
    "        )\n",
    "        final_response = llm.invoke(direct_prompt)\n",
    "    \n",
    "    return final_response\n",
    "\n",
    "\n",
    "# --- Define the Answer Generation Function without RAG ---\n",
    "def generate_answer_without_rag(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Generates a detailed and accurate answer to the user's query without using any additional context from external documents.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The user's query to answer.\n",
    "\n",
    "    Returns:\n",
    "        str: The generated answer based on the query.\n",
    "    \"\"\"\n",
    "    direct_prompt = (\n",
    "        \"Please provide a detailed and accurate answer to the following query:\\n\"\n",
    "        f\"{query}\\n\"\n",
    "        \"Answer:\"\n",
    "    )\n",
    "    final_response = llm.invoke(direct_prompt)\n",
    "    \n",
    "    return final_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 💡 Step 9: Answer Generation with Agentic RAG\n",
    "\n",
    "If additional context is needed, the model retrieves **relevant document chunks** and incorporates them into the response prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What are the key features of Z by HP AI Studio?\"\n",
    "print(\"User Query:\", query)\n",
    "final_answer = generate_answer_with_agentic_rag(query)\n",
    "print(\"\\nFinal Answer:\")\n",
    "print(final_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ⚡ Step 10: Answer Generation Without RAG\n",
    "\n",
    "In this case, we generate an answer without using RAG to show the difference between 2 answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What are the key features of Z by HP AI Studio?\"\n",
    "print(\"User Query:\", query)\n",
    "final_answer = generate_answer_without_rag(query)\n",
    "print(\"\\nFinal Answer:\")\n",
    "print(final_answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
