{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf9b63a5",
   "metadata": {},
   "source": [
    "# üéõÔ∏è Orpheus Engine Web Demo\n",
    "\n",
    "Interactive demonstration of Orpheus Engine DAW components showcasing platform capabilities and cross-platform compatibility.\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook demonstrates:\n",
    "- **Platform Detection**: Automatic detection of Electron, Browser, and Python environments\n",
    "- **Component Showcase**: Interactive DAW widgets and interfaces\n",
    "- **Capability Testing**: Real-time testing of audio, file system, and notification APIs\n",
    "- **Cross-Platform Compatibility**: Seamless operation across different platforms\n",
    "\n",
    "**Compatible Environments**: Jupyter Lab, Jupyter Notebook, VS Code Jupyter, Google Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade05a5c",
   "metadata": {},
   "source": [
    "## üîß Installation & Setup\n",
    "\n",
    "### Prerequisites\n",
    "- **Python 3.8+** (Python 3.9+ recommended)\n",
    "- **Jupyter Lab or Jupyter Notebook**\n",
    "- **Git** (for cloning the repository)\n",
    "- **FFmpeg** (for audio processing)\n",
    "\n",
    "### Quick Installation\n",
    "\n",
    "#### Option 1: Install from requirements.txt (Recommended)\n",
    "```bash\n",
    "# Navigate to the demo directory\n",
    "cd demo/\n",
    "\n",
    "# Install all dependencies including TensorFlow and MLflow\n",
    "pip install -r requirements.txt\n",
    "\n",
    "# Install TensorFlow and additional ML packages\n",
    "pip install tensorflow>=2.13.0 torch>=2.0.0\n",
    "```\n",
    "\n",
    "#### Option 2: Manual Installation\n",
    "```bash\n",
    "# Core ML and tracking\n",
    "pip install mlflow>=2.8.0 mlflow-ui>=2.8.0\n",
    "\n",
    "# TensorFlow and PyTorch for deep learning\n",
    "pip install tensorflow>=2.13.0 torch>=2.0.0 torchvision torchaudio\n",
    "\n",
    "# Audio processing libraries\n",
    "pip install librosa>=0.10.0 soundfile>=0.12.0 scipy>=1.10.0\n",
    "\n",
    "# Data science stack\n",
    "pip install numpy>=1.24.0 pandas>=2.0.0 scikit-learn>=1.3.0\n",
    "\n",
    "# Visualization\n",
    "pip install matplotlib>=3.6.0 seaborn>=0.12.0 plotly>=5.17.0\n",
    "\n",
    "# Jupyter ecosystem\n",
    "pip install jupyter>=1.0.0 ipywidgets>=8.0.0\n",
    "\n",
    "# Web APIs\n",
    "pip install fastapi>=0.104.0 uvicorn>=0.24.0 requests>=2.31.0\n",
    "```\n",
    "\n",
    "### System-Specific Setup\n",
    "\n",
    "#### macOS\n",
    "```bash\n",
    "# Install FFmpeg and system dependencies\n",
    "brew install ffmpeg portaudio\n",
    "\n",
    "# For Apple Silicon Macs\n",
    "export ARCHFLAGS=\"-arch arm64\"\n",
    "pip install --no-cache-dir tensorflow librosa soundfile\n",
    "```\n",
    "\n",
    "#### Ubuntu/Debian\n",
    "```bash\n",
    "# Install system dependencies\n",
    "sudo apt-get update\n",
    "sudo apt-get install ffmpeg libsndfile1 portaudio19-dev python3-dev\n",
    "\n",
    "# Install Python packages\n",
    "pip install -r requirements.txt\n",
    "pip install tensorflow torch\n",
    "```\n",
    "\n",
    "#### Windows\n",
    "```bash\n",
    "# Using conda (recommended for Windows)\n",
    "conda install -c conda-forge librosa soundfile ffmpeg\n",
    "pip install tensorflow torch mlflow jupyter plotly\n",
    "```\n",
    "\n",
    "### MLflow Setup\n",
    "\n",
    "```bash\n",
    "# Start MLflow tracking server (run in separate terminal)\n",
    "mlflow server --host 127.0.0.1 --port 5000\n",
    "\n",
    "# Or start with specific backend store\n",
    "mlflow server --backend-store-uri sqlite:///mlflow.db --default-artifact-root ./mlruns --host 127.0.0.1 --port 5000\n",
    "```\n",
    "\n",
    "### Verification\n",
    "Run the next cell to verify your installation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe991b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîç Installation Verification & Environment Setup\n",
    "# Run this cell to verify all dependencies and start MLflow\n",
    "\n",
    "import sys\n",
    "import subprocess\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Core package verification\n",
    "required_packages = {\n",
    "    'numpy': 'Numerical computing',\n",
    "    'pandas': 'Data manipulation', \n",
    "    'matplotlib': 'Basic plotting',\n",
    "    'seaborn': 'Statistical visualization',\n",
    "    'plotly': 'Interactive visualization',\n",
    "    'sklearn': 'Machine learning',\n",
    "    'librosa': 'Audio analysis',\n",
    "    'soundfile': 'Audio I/O',\n",
    "    'scipy': 'Scientific computing',\n",
    "    'mlflow': 'Experiment tracking',\n",
    "    'fastapi': 'Web API framework',\n",
    "    'uvicorn': 'ASGI server',\n",
    "    'requests': 'HTTP client',\n",
    "    'jupyter': 'Jupyter ecosystem',\n",
    "    'ipywidgets': 'Interactive widgets'\n",
    "}\n",
    "\n",
    "# Test TensorFlow and PyTorch separately\n",
    "ml_frameworks = {\n",
    "    'tensorflow': 'Deep learning framework (Google)',\n",
    "    'torch': 'Deep learning framework (PyTorch)'\n",
    "}\n",
    "\n",
    "success_count = 0\n",
    "total_count = len(required_packages) + len(ml_frameworks)\n",
    "\n",
    "print(\"üì¶ Core Packages:\")\n",
    "for package, description in required_packages.items():\n",
    "    try:\n",
    "        if package == 'sklearn':\n",
    "            import sklearn\n",
    "        else:\n",
    "            __import__(package)\n",
    "        print(f\"‚úÖ {package:<15} - {description}\")\n",
    "        success_count += 1\n",
    "    except ImportError:\n",
    "        print(f\"‚ùå {package:<15} - {description} (MISSING)\")\n",
    "        print(f\"   Install with: pip install {package}\")\n",
    "\n",
    "print(\"\\nü§ñ ML Frameworks:\")\n",
    "for framework, description in ml_frameworks.items():\n",
    "    try:\n",
    "        if framework == 'tensorflow':\n",
    "            import tensorflow as tf\n",
    "            print(f\"‚úÖ {framework:<15} - {description} (v{tf.__version__})\")\n",
    "            # Test GPU availability\n",
    "            if tf.config.list_physical_devices('GPU'):\n",
    "                print(f\"   üöÄ GPU acceleration available: {len(tf.config.list_physical_devices('GPU'))} GPU(s)\")\n",
    "            else:\n",
    "                print(f\"   üíª CPU-only mode (no GPU detected)\")\n",
    "        elif framework == 'torch':\n",
    "            import torch\n",
    "            print(f\"‚úÖ {framework:<15} - {description} (v{torch.__version__})\")\n",
    "            if torch.cuda.is_available():\n",
    "                print(f\"   üöÄ CUDA available: {torch.cuda.device_count()} GPU(s)\")\n",
    "            elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "                print(f\"   üçé Apple Silicon GPU (MPS) available\")\n",
    "            else:\n",
    "                print(f\"   üíª CPU-only mode\")\n",
    "        success_count += 1\n",
    "    except ImportError:\n",
    "        print(f\"‚ùå {framework:<15} - {description} (MISSING)\")\n",
    "        print(f\"   Install with: pip install {framework}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  {framework:<15} - {description} (INSTALLED but issue: {str(e)[:50]}...)\")\n",
    "        success_count += 1  # Count as success since it's installed\n",
    "\n",
    "print(\"=\" * 60)\n",
    "if success_count >= len(required_packages):  # Allow missing ML frameworks\n",
    "    print(f\"üéâ SUCCESS: Core packages ready! ({success_count}/{total_count} total packages)\")\n",
    "    print(\"You can proceed with the Orpheus Engine demo.\")\n",
    "else:\n",
    "    missing = len(required_packages) + len(ml_frameworks) - success_count\n",
    "    print(f\"‚ö†Ô∏è  WARNING: {missing} packages are missing.\")\n",
    "    print(\"Please install missing packages before continuing.\")\n",
    "    print(\"\\nQuick fix: cd demo && pip install -r requirements.txt && pip install tensorflow torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fd995e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üöÄ MLflow Startup and Configuration\n",
    "# Initialize MLflow tracking for the Orpheus Engine demo\n",
    "\n",
    "import mlflow\n",
    "import mlflow.tensorflow\n",
    "import mlflow.pytorch\n",
    "import mlflow.sklearn\n",
    "from mlflow.tracking import MlflowClient\n",
    "import subprocess\n",
    "import time\n",
    "import socket\n",
    "from datetime import datetime\n",
    "import threading\n",
    "import os\n",
    "\n",
    "def check_port_available(port):\n",
    "    \"\"\"Check if a port is available\"\"\"\n",
    "    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
    "        try:\n",
    "            s.bind(('127.0.0.1', port))\n",
    "            return True\n",
    "        except OSError:\n",
    "            return False\n",
    "\n",
    "def start_mlflow_server(port=5000):\n",
    "    \"\"\"Start MLflow tracking server if not already running\"\"\"\n",
    "    if not check_port_available(port):\n",
    "        print(f\"‚úÖ MLflow server already running on port {port}\")\n",
    "        return True\n",
    "    \n",
    "    try:\n",
    "        # Create mlruns directory if it doesn't exist\n",
    "        mlruns_dir = Path.cwd() / \"mlruns\"\n",
    "        mlruns_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        print(f\"üöÄ Starting MLflow server on port {port}...\")\n",
    "        \n",
    "        # Start MLflow server in background\n",
    "        cmd = [\n",
    "            sys.executable, \"-m\", \"mlflow\", \"server\",\n",
    "            \"--host\", \"127.0.0.1\",\n",
    "            \"--port\", str(port),\n",
    "            \"--backend-store-uri\", f\"sqlite:///{mlruns_dir}/mlflow.db\",\n",
    "            \"--default-artifact-root\", str(mlruns_dir)\n",
    "        ]\n",
    "        \n",
    "        # Start process in background\n",
    "        process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        \n",
    "        # Wait a moment for server to start\n",
    "        time.sleep(3)\n",
    "        \n",
    "        # Check if server is running\n",
    "        if not check_port_available(port):\n",
    "            print(f\"‚úÖ MLflow server started successfully on http://127.0.0.1:{port}\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"‚ùå Failed to start MLflow server\")\n",
    "            return False\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error starting MLflow server: {e}\")\n",
    "        print(\"üí° You can start manually: mlflow server --host 127.0.0.1 --port 5000\")\n",
    "        return False\n",
    "\n",
    "# MLflow Configuration\n",
    "MLFLOW_PORT = 5000\n",
    "MLFLOW_URI = f\"http://127.0.0.1:{MLFLOW_PORT}\"\n",
    "EXPERIMENT_NAME = \"Orpheus_Engine_Web_Demo\"\n",
    "\n",
    "print(\"üîß MLflow Configuration:\")\n",
    "print(f\"   Tracking URI: {MLFLOW_URI}\")\n",
    "print(f\"   Experiment: {EXPERIMENT_NAME}\")\n",
    "print(f\"   Artifacts: ./mlruns\")\n",
    "print()\n",
    "\n",
    "# Start MLflow server\n",
    "mlflow_running = start_mlflow_server(MLFLOW_PORT)\n",
    "\n",
    "if mlflow_running:\n",
    "    # Configure MLflow\n",
    "    mlflow.set_tracking_uri(MLFLOW_URI)\n",
    "    \n",
    "    try:\n",
    "        # Create or get experiment\n",
    "        experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "        if experiment is None:\n",
    "            experiment_id = mlflow.create_experiment(EXPERIMENT_NAME)\n",
    "            print(f\"‚úÖ Created new experiment: {EXPERIMENT_NAME} (ID: {experiment_id})\")\n",
    "        else:\n",
    "            experiment_id = experiment.experiment_id\n",
    "            print(f\"‚úÖ Using existing experiment: {EXPERIMENT_NAME} (ID: {experiment_id})\")\n",
    "        \n",
    "        mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "        \n",
    "        # Test connection\n",
    "        client = MlflowClient(MLFLOW_URI)\n",
    "        experiments = client.search_experiments()\n",
    "        print(f\"‚úÖ MLflow connection successful - Found {len(experiments)} experiments\")\n",
    "        \n",
    "        print(f\"\\nüåê MLflow UI available at: {MLFLOW_URI}\")\n",
    "        print(\"   Click the link above to view experiments in your browser\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  MLflow configuration issue: {e}\")\n",
    "        print(\"   Demo will continue without MLflow tracking\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  MLflow server not available - continuing without experiment tracking\")\n",
    "    print(\"   You can start MLflow manually and restart this notebook\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéµ Orpheus Engine Demo Environment Ready!\")\n",
    "print(\"üìä Experiment tracking:\", \"‚úÖ Enabled\" if mlflow_running else \"‚ùå Disabled\")\n",
    "print(\"ü§ñ ML Frameworks:\", \"TensorFlow + PyTorch\" if 'tensorflow' in sys.modules and 'torch' in sys.modules else \"Limited\")\n",
    "print(\"üèõÔ∏è Ready for DAW demonstrations and ML experiments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493362ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries and setup environment\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML, Javascript, display, Audio\n",
    "from IPython.core.magic import Magics, magics_class, line_magic, cell_magic\n",
    "\n",
    "# Add project root to path for importing Orpheus modules\n",
    "project_root = Path.cwd()\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(\"üéµ Orpheus Engine Web Demo Environment Initialized\")\n",
    "print(f\"üìÅ Project Root: {project_root}\")\n",
    "print(f\"üêç Python Version: {sys.version}\")\n",
    "print(f\"üìì Jupyter Environment: {'JupyterLab' if 'JUPYTERHUB_SERVICE_PREFIX' in os.environ else 'Jupyter Notebook'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e093540b",
   "metadata": {},
   "source": [
    "## üîß Platform Detection and Capabilities\n",
    "\n",
    "Let's start by detecting the current platform and testing available capabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f63b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Platform capability detection\n",
    "def detect_platform_capabilities():\n",
    "    \"\"\"Detect and test platform capabilities for DAW functionality\"\"\"\n",
    "    \n",
    "    capabilities = {\n",
    "        'python_backend': True,  # Always true in Jupyter\n",
    "        'audio_processing': False,\n",
    "        'file_system': True,\n",
    "        'data_visualization': False,\n",
    "        'machine_learning': False,\n",
    "        'web_components': False\n",
    "    }\n",
    "    \n",
    "    # Test audio processing libraries\n",
    "    try:\n",
    "        import librosa\n",
    "        import soundfile as sf\n",
    "        capabilities['audio_processing'] = True\n",
    "        print(\"‚úÖ Audio Processing: librosa, soundfile available\")\n",
    "    except ImportError:\n",
    "        print(\"‚ùå Audio Processing: Install librosa and soundfile\")\n",
    "    \n",
    "    # Test data visualization\n",
    "    try:\n",
    "        import matplotlib.pyplot as plt\n",
    "        import seaborn as sns\n",
    "        capabilities['data_visualization'] = True\n",
    "        print(\"‚úÖ Data Visualization: matplotlib, seaborn available\")\n",
    "    except ImportError:\n",
    "        print(\"‚ùå Data Visualization: Install matplotlib and seaborn\")\n",
    "    \n",
    "    # Test machine learning capabilities\n",
    "    try:\n",
    "        import sklearn\n",
    "        import pandas as pd\n",
    "        capabilities['machine_learning'] = True\n",
    "        print(\"‚úÖ Machine Learning: scikit-learn, pandas available\")\n",
    "    except ImportError:\n",
    "        print(\"‚ùå Machine Learning: Install scikit-learn and pandas\")\n",
    "    \n",
    "    # Test web components support\n",
    "    try:\n",
    "        from IPython.display import HTML, Javascript\n",
    "        capabilities['web_components'] = True\n",
    "        print(\"‚úÖ Web Components: IPython display available\")\n",
    "    except ImportError:\n",
    "        print(\"‚ùå Web Components: IPython not available\")\n",
    "    \n",
    "    return capabilities\n",
    "\n",
    "# Run capability detection\n",
    "platform_caps = detect_platform_capabilities()\n",
    "print(f\"\\nüìä Platform Capabilities Summary:\")\n",
    "for cap, available in platform_caps.items():\n",
    "    status = \"‚úÖ\" if available else \"‚ùå\"\n",
    "    print(f\"{status} {cap.replace('_', ' ').title()}: {available}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f3f0fb",
   "metadata": {},
   "source": [
    "## üéõÔ∏è Interactive DAW Components\n",
    "\n",
    "Now let's create interactive web components that simulate DAW functionality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4beddef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_daw_interface():\n",
    "    \"\"\"Create an interactive DAW interface using HTML/CSS/JavaScript\"\"\"\n",
    "    \n",
    "    daw_html = \"\"\"\n",
    "    <div id=\"orpheus-daw-demo\" style=\"\n",
    "        width: 100%; \n",
    "        background: linear-gradient(135deg, #1e1e1e 0%, #2a2a2a 100%); \n",
    "        color: white; \n",
    "        font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;\n",
    "        border-radius: 12px; \n",
    "        padding: 20px; \n",
    "        margin: 10px 0;\n",
    "        box-shadow: 0 4px 20px rgba(0,0,0,0.3);\n",
    "    \">\n",
    "        <div style=\"text-align: center; margin-bottom: 30px;\">\n",
    "            <h1 style=\"\n",
    "                background: linear-gradient(45deg, #ff6b6b, #4ecdc4); \n",
    "                -webkit-background-clip: text; \n",
    "                -webkit-text-fill-color: transparent; \n",
    "                background-clip: text; \n",
    "                margin: 0; \n",
    "                font-size: 2.5rem;\n",
    "            \">Orpheus Engine Demo</h1>\n",
    "            <p style=\"color: #888; margin: 10px 0;\">Interactive DAW Components</p>\n",
    "        </div>\n",
    "        \n",
    "        <!-- Platform Info Panel -->\n",
    "        <div style=\"background: rgba(0,0,0,0.3); border-radius: 8px; padding: 16px; margin-bottom: 20px;\">\n",
    "            <h3 style=\"color: #4ecdc4; margin-top: 0;\">Platform Information</h3>\n",
    "            <div id=\"platform-info\" style=\"display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 10px;\">\n",
    "                <div style=\"background: rgba(78, 205, 196, 0.2); padding: 10px; border-radius: 6px; border: 1px solid #4ecdc4;\">\n",
    "                    <strong>Environment:</strong> Jupyter Notebook\n",
    "                </div>\n",
    "                <div style=\"background: rgba(78, 205, 196, 0.2); padding: 10px; border-radius: 6px; border: 1px solid #4ecdc4;\">\n",
    "                    <strong>Backend:</strong> Python\n",
    "                </div>\n",
    "                <div style=\"background: rgba(78, 205, 196, 0.2); padding: 10px; border-radius: 6px; border: 1px solid #4ecdc4;\">\n",
    "                    <strong>Frontend:</strong> HTML/JS\n",
    "                </div>\n",
    "            </div>\n",
    "        </div>\n",
    "        \n",
    "        <!-- Transport Controls -->\n",
    "        <div style=\"background: rgba(0,0,0,0.3); border-radius: 8px; padding: 16px; margin-bottom: 20px;\">\n",
    "            <h3 style=\"color: #4ecdc4; margin-top: 0;\">Transport Controls</h3>\n",
    "            <div style=\"display: flex; align-items: center; gap: 12px; margin-bottom: 16px;\">\n",
    "                <button onclick=\"togglePlayback()\" id=\"play-btn\" style=\"\n",
    "                    width: 50px; height: 50px; border-radius: 50%; background: #4ecdc4; \n",
    "                    border: none; color: #1e1e1e; font-size: 1.5rem; cursor: pointer;\n",
    "                    transition: all 0.2s;\n",
    "                \" onmouseover=\"this.style.background='#45b7aa'\" onmouseout=\"this.style.background='#4ecdc4'\">\n",
    "                    ‚ñ∂Ô∏è\n",
    "                </button>\n",
    "                <button onclick=\"stopPlayback()\" style=\"\n",
    "                    width: 40px; height: 40px; border-radius: 6px; background: #ff6b6b; \n",
    "                    border: none; color: white; font-size: 1.2rem; cursor: pointer;\n",
    "                \">‚èπÔ∏è</button>\n",
    "                <span id=\"time-display\" style=\"\n",
    "                    font-family: monospace; background: rgba(0,0,0,0.5); \n",
    "                    padding: 8px 16px; border-radius: 4px; min-width: 100px; text-align: center;\n",
    "                \">00:00.0</span>\n",
    "                <div style=\"flex: 1; height: 6px; background: #333; border-radius: 3px; position: relative;\">\n",
    "                    <div id=\"progress-bar\" style=\"\n",
    "                        height: 100%; background: #4ecdc4; border-radius: 3px; width: 0%; \n",
    "                        transition: width 0.1s;\n",
    "                    \"></div>\n",
    "                </div>\n",
    "            </div>\n",
    "        </div>\n",
    "        \n",
    "        <!-- Timeline/Tracks -->\n",
    "        <div style=\"background: rgba(0,0,0,0.3); border-radius: 8px; padding: 16px; margin-bottom: 20px;\">\n",
    "            <h3 style=\"color: #4ecdc4; margin-top: 0;\">Timeline & Tracks</h3>\n",
    "            <div style=\"background: #2a2a2a; border-radius: 6px; padding: 12px; min-height: 160px; position: relative;\">\n",
    "                <div id=\"playhead\" style=\"\n",
    "                    position: absolute; top: 0; width: 2px; height: 100%; \n",
    "                    background: #ff6b6b; z-index: 10; left: 0; transition: left 0.1s;\n",
    "                \"></div>\n",
    "                \n",
    "                <!-- Track 1 -->\n",
    "                <div style=\"height: 40px; border-bottom: 1px solid #444; position: relative; margin-bottom: 8px;\">\n",
    "                    <div style=\"\n",
    "                        position: absolute; left: 10%; width: 25%; height: 30px; top: 5px;\n",
    "                        background: linear-gradient(45deg, #4ecdc4, #45b7aa); border-radius: 4px;\n",
    "                        display: flex; align-items: center; justify-content: center; font-size: 0.8rem;\n",
    "                    \">Kick Drum</div>\n",
    "                    <span style=\"position: absolute; left: 8px; top: 50%; transform: translateY(-50%); font-size: 0.9rem;\">\n",
    "                        Track 1\n",
    "                    </span>\n",
    "                </div>\n",
    "                \n",
    "                <!-- Track 2 -->\n",
    "                <div style=\"height: 40px; border-bottom: 1px solid #444; position: relative; margin-bottom: 8px;\">\n",
    "                    <div style=\"\n",
    "                        position: absolute; left: 20%; width: 35%; height: 30px; top: 5px;\n",
    "                        background: linear-gradient(45deg, #ff6b6b, #ff5555); border-radius: 4px;\n",
    "                        display: flex; align-items: center; justify-content: center; font-size: 0.8rem;\n",
    "                    \">Bass Synth</div>\n",
    "                    <span style=\"position: absolute; left: 8px; top: 50%; transform: translateY(-50%); font-size: 0.9rem;\">\n",
    "                        Track 2\n",
    "                    </span>\n",
    "                </div>\n",
    "                \n",
    "                <!-- Track 3 -->\n",
    "                <div style=\"height: 40px; position: relative;\">\n",
    "                    <div style=\"\n",
    "                        position: absolute; left: 40%; width: 40%; height: 30px; top: 5px;\n",
    "                        background: linear-gradient(45deg, #9b59b6, #8e44ad); border-radius: 4px;\n",
    "                        display: flex; align-items: center; justify-content: center; font-size: 0.8rem;\n",
    "                    \">Lead Vocal</div>\n",
    "                    <span style=\"position: absolute; left: 8px; top: 50%; transform: translateY(-50%); font-size: 0.9rem;\">\n",
    "                        Track 3\n",
    "                    </span>\n",
    "                </div>\n",
    "            </div>\n",
    "        </div>\n",
    "        \n",
    "        <!-- Mixer Panel -->\n",
    "        <div style=\"background: rgba(0,0,0,0.3); border-radius: 8px; padding: 16px;\">\n",
    "            <h3 style=\"color: #4ecdc4; margin-top: 0;\">Mixer</h3>\n",
    "            <div style=\"display: flex; justify-content: space-around; align-items: end;\">\n",
    "                <!-- Channel 1 -->\n",
    "                <div style=\"display: flex; flex-direction: column; align-items: center; gap: 10px;\">\n",
    "                    <div id=\"meter-1\" style=\"width: 20px; height: 100px; background: #333; border-radius: 10px; position: relative; overflow: hidden;\">\n",
    "                        <div style=\"position: absolute; bottom: 0; width: 100%; background: linear-gradient(to top, #4ecdc4, #ff6b6b); height: 0%; transition: height 0.1s;\" id=\"meter-1-level\"></div>\n",
    "                    </div>\n",
    "                    <input type=\"range\" min=\"0\" max=\"100\" value=\"75\" style=\"writing-mode: bt-lr; -webkit-appearance: slider-vertical; width: 20px; height: 80px;\" oninput=\"updateChannelVolume(1, this.value)\">\n",
    "                    <span style=\"font-size: 0.8rem;\">Ch 1</span>\n",
    "                </div>\n",
    "                \n",
    "                <!-- Channel 2 -->\n",
    "                <div style=\"display: flex; flex-direction: column; align-items: center; gap: 10px;\">\n",
    "                    <div id=\"meter-2\" style=\"width: 20px; height: 100px; background: #333; border-radius: 10px; position: relative; overflow: hidden;\">\n",
    "                        <div style=\"position: absolute; bottom: 0; width: 100%; background: linear-gradient(to top, #4ecdc4, #ff6b6b); height: 0%; transition: height 0.1s;\" id=\"meter-2-level\"></div>\n",
    "                    </div>\n",
    "                    <input type=\"range\" min=\"0\" max=\"100\" value=\"68\" style=\"writing-mode: bt-lr; -webkit-appearance: slider-vertical; width: 20px; height: 80px;\" oninput=\"updateChannelVolume(2, this.value)\">\n",
    "                    <span style=\"font-size: 0.8rem;\">Ch 2</span>\n",
    "                </div>\n",
    "                \n",
    "                <!-- Channel 3 -->\n",
    "                <div style=\"display: flex; flex-direction: column; align-items: center; gap: 10px;\">\n",
    "                    <div id=\"meter-3\" style=\"width: 20px; height: 100px; background: #333; border-radius: 10px; position: relative; overflow: hidden;\">\n",
    "                        <div style=\"position: absolute; bottom: 0; width: 100%; background: linear-gradient(to top, #4ecdc4, #ff6b6b); height: 0%; transition: height 0.1s;\" id=\"meter-3-level\"></div>\n",
    "                    </div>\n",
    "                    <input type=\"range\" min=\"0\" max=\"100\" value=\"82\" style=\"writing-mode: bt-lr; -webkit-appearance: slider-vertical; width: 20px; height: 80px;\" oninput=\"updateChannelVolume(3, this.value)\">\n",
    "                    <span style=\"font-size: 0.8rem;\">Ch 3</span>\n",
    "                </div>\n",
    "                \n",
    "                <!-- Master -->\n",
    "                <div style=\"display: flex; flex-direction: column; align-items: center; gap: 10px; border-left: 2px solid #444; padding-left: 20px; margin-left: 15px;\">\n",
    "                    <div id=\"master-meter\" style=\"width: 25px; height: 100px; background: #333; border-radius: 10px; position: relative; overflow: hidden;\">\n",
    "                        <div style=\"position: absolute; bottom: 0; width: 100%; background: linear-gradient(to top, #4ecdc4, #ff6b6b); height: 0%; transition: height 0.1s;\" id=\"master-meter-level\"></div>\n",
    "                    </div>\n",
    "                    <input type=\"range\" min=\"0\" max=\"100\" value=\"85\" style=\"writing-mode: bt-lr; -webkit-appearance: slider-vertical; width: 25px; height: 80px;\" oninput=\"updateMasterVolume(this.value)\">\n",
    "                    <span style=\"font-size: 0.9rem; font-weight: bold;\">Master</span>\n",
    "                </div>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "    \n",
    "    <script>\n",
    "        let isPlaying = false;\n",
    "        let currentTime = 0;\n",
    "        let playInterval = null;\n",
    "        let meterInterval = null;\n",
    "        \n",
    "        function togglePlayback() {\n",
    "            const playBtn = document.getElementById('play-btn');\n",
    "            const timeDisplay = document.getElementById('time-display');\n",
    "            const progressBar = document.getElementById('progress-bar');\n",
    "            const playhead = document.getElementById('playhead');\n",
    "            \n",
    "            if (isPlaying) {\n",
    "                // Stop playback\n",
    "                isPlaying = false;\n",
    "                playBtn.innerHTML = '‚ñ∂Ô∏è';\n",
    "                clearInterval(playInterval);\n",
    "                clearInterval(meterInterval);\n",
    "            } else {\n",
    "                // Start playback\n",
    "                isPlaying = true;\n",
    "                playBtn.innerHTML = '‚è∏Ô∏è';\n",
    "                \n",
    "                // Update time and progress\n",
    "                playInterval = setInterval(() => {\n",
    "                    currentTime += 0.1;\n",
    "                    const minutes = Math.floor(currentTime / 60);\n",
    "                    const seconds = (currentTime % 60).toFixed(1);\n",
    "                    timeDisplay.textContent = `${minutes.toString().padStart(2, '0')}:${seconds.padStart(4, '0')}`;\n",
    "                    \n",
    "                    // Update progress bar (assuming 30 second loop)\n",
    "                    const progress = (currentTime % 30) / 30 * 100;\n",
    "                    progressBar.style.width = progress + '%';\n",
    "                    playhead.style.left = progress + '%';\n",
    "                    \n",
    "                    // Loop back to start after 30 seconds\n",
    "                    if (currentTime >= 30) currentTime = 0;\n",
    "                }, 100);\n",
    "                \n",
    "                // Animate meters\n",
    "                meterInterval = setInterval(() => {\n",
    "                    for (let i = 1; i <= 3; i++) {\n",
    "                        const level = Math.random() * 70 + 20; // 20-90%\n",
    "                        document.getElementById(`meter-${i}-level`).style.height = level + '%';\n",
    "                    }\n",
    "                    const masterLevel = Math.random() * 80 + 15; // 15-95%\n",
    "                    document.getElementById('master-meter-level').style.height = masterLevel + '%';\n",
    "                }, 50);\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        function stopPlayback() {\n",
    "            isPlaying = false;\n",
    "            currentTime = 0;\n",
    "            document.getElementById('play-btn').innerHTML = '‚ñ∂Ô∏è';\n",
    "            document.getElementById('time-display').textContent = '00:00.0';\n",
    "            document.getElementById('progress-bar').style.width = '0%';\n",
    "            document.getElementById('playhead').style.left = '0%';\n",
    "            clearInterval(playInterval);\n",
    "            clearInterval(meterInterval);\n",
    "            \n",
    "            // Reset meters\n",
    "            for (let i = 1; i <= 3; i++) {\n",
    "                document.getElementById(`meter-${i}-level`).style.height = '0%';\n",
    "            }\n",
    "            document.getElementById('master-meter-level').style.height = '0%';\n",
    "        }\n",
    "        \n",
    "        function updateChannelVolume(channel, value) {\n",
    "            console.log(`Channel ${channel} volume: ${value}%`);\n",
    "        }\n",
    "        \n",
    "        function updateMasterVolume(value) {\n",
    "            console.log(`Master volume: ${value}%`);\n",
    "        }\n",
    "    </script>\n",
    "    \"\"\"\n",
    "    \n",
    "    return HTML(daw_html)\n",
    "\n",
    "# Display the DAW interface\n",
    "create_daw_interface()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6827163",
   "metadata": {},
   "source": [
    "## üéµ Audio Processing Demo\n",
    "\n",
    "Let's demonstrate audio processing capabilities using Python libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76452d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio processing and waveform generation\n",
    "def create_audio_demo():\n",
    "    \"\"\"Create audio waveforms and demonstrate processing\"\"\"\n",
    "    \n",
    "    if not platform_caps.get('audio_processing', False):\n",
    "        print(\"‚ùå Audio processing libraries not available. Install librosa and soundfile:\")\n",
    "        print(\"pip install librosa soundfile\")\n",
    "        return\n",
    "    \n",
    "    # Generate test audio signals\n",
    "    sample_rate = 44100\n",
    "    duration = 3.0  # seconds\n",
    "    t = np.linspace(0, duration, int(sample_rate * duration), False)\n",
    "    \n",
    "    # Create different waveforms\n",
    "    kick_drum = np.sin(2 * np.pi * 60 * t) * np.exp(-t * 10) * 0.8  # Exponential decay\n",
    "    bass_synth = np.sin(2 * np.pi * 80 * t) * 0.6  # Sine wave\n",
    "    lead_vocal = np.sin(2 * np.pi * 220 * t + np.sin(2 * np.pi * 5 * t)) * 0.4  # FM synthesis\n",
    "    \n",
    "    # Mix the signals\n",
    "    mix = (kick_drum + bass_synth + lead_vocal) / 3\n",
    "    \n",
    "    # Apply some basic effects\n",
    "    # Simple low-pass filter\n",
    "    from scipy import signal\n",
    "    b, a = signal.butter(4, 0.1)\n",
    "    filtered_mix = signal.filtfilt(b, a, mix)\n",
    "    \n",
    "    # Plot waveforms\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    plt.subplot(3, 2, 1)\n",
    "    plt.plot(t[:1000], kick_drum[:1000], color='#4ecdc4', linewidth=2)\n",
    "    plt.title('Track 1: Kick Drum', fontsize=12, color='#4ecdc4')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.subplot(3, 2, 2)\n",
    "    plt.plot(t[:1000], bass_synth[:1000], color='#ff6b6b', linewidth=2)\n",
    "    plt.title('Track 2: Bass Synth', fontsize=12, color='#ff6b6b')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.subplot(3, 2, 3)\n",
    "    plt.plot(t[:1000], lead_vocal[:1000], color='#9b59b6', linewidth=2)\n",
    "    plt.title('Track 3: Lead Vocal', fontsize=12, color='#9b59b6')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.subplot(3, 2, 4)\n",
    "    plt.plot(t[:1000], mix[:1000], color='#f39c12', linewidth=2)\n",
    "    plt.title('Mixed Output', fontsize=12, color='#f39c12')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Frequency analysis\n",
    "    plt.subplot(3, 2, 5)\n",
    "    f, Pxx = signal.welch(mix, sample_rate, nperseg=2048)\n",
    "    plt.semilogy(f, Pxx, color='#e74c3c', linewidth=2)\n",
    "    plt.title('Frequency Spectrum', fontsize=12, color='#e74c3c')\n",
    "    plt.xlabel('Frequency (Hz)')\n",
    "    plt.ylabel('Power Spectral Density')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.xlim(0, 1000)\n",
    "    \n",
    "    # Filtered version\n",
    "    plt.subplot(3, 2, 6)\n",
    "    plt.plot(t[:1000], filtered_mix[:1000], color='#27ae60', linewidth=2)\n",
    "    plt.title('Filtered Mix (Low-pass)', fontsize=12, color='#27ae60')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Return audio for playback\n",
    "    return {\n",
    "        'sample_rate': sample_rate,\n",
    "        'kick_drum': kick_drum,\n",
    "        'bass_synth': bass_synth,\n",
    "        'lead_vocal': lead_vocal,\n",
    "        'mix': mix,\n",
    "        'filtered_mix': filtered_mix\n",
    "    }\n",
    "\n",
    "# Generate and display audio demo\n",
    "audio_data = create_audio_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c965e3ba",
   "metadata": {},
   "source": [
    "## üéß Audio Playback\n",
    "\n",
    "Listen to the generated audio tracks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8f9054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio playback functionality\n",
    "if audio_data and platform_caps.get('audio_processing', False):\n",
    "    print(\"üéµ Generated Audio Tracks:\")\n",
    "    print(\"Click on any audio player below to listen to the generated sounds\")\n",
    "    \n",
    "    # Display audio players for each track\n",
    "    display(HTML(\"<h4 style='color: #4ecdc4;'>ü•Å Track 1: Kick Drum</h4>\"))\n",
    "    display(Audio(audio_data['kick_drum'], rate=audio_data['sample_rate']))\n",
    "    \n",
    "    display(HTML(\"<h4 style='color: #ff6b6b;'>üéπ Track 2: Bass Synth</h4>\"))\n",
    "    display(Audio(audio_data['bass_synth'], rate=audio_data['sample_rate']))\n",
    "    \n",
    "    display(HTML(\"<h4 style='color: #9b59b6;'>üé§ Track 3: Lead Vocal</h4>\"))\n",
    "    display(Audio(audio_data['lead_vocal'], rate=audio_data['sample_rate']))\n",
    "    \n",
    "    display(HTML(\"<h4 style='color: #f39c12;'>üéõÔ∏è Mixed Output</h4>\"))\n",
    "    display(Audio(audio_data['mix'], rate=audio_data['sample_rate']))\n",
    "    \n",
    "    display(HTML(\"<h4 style='color: #27ae60;'>üîä Filtered Mix</h4>\"))\n",
    "    display(Audio(audio_data['filtered_mix'], rate=audio_data['sample_rate']))\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Audio playback requires audio processing libraries\")\n",
    "    print(\"Install with: pip install librosa soundfile\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4c548e",
   "metadata": {},
   "source": [
    "## üìä Platform Integration Test\n",
    "\n",
    "Test integration between the web interface and Python backend:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6362c57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Platform integration testing\n",
    "def test_platform_integration():\n",
    "    \"\"\"Test integration between frontend and backend components\"\"\"\n",
    "    \n",
    "    print(\"üîÑ Testing Platform Integration...\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Test 1: Data sharing between Python and JavaScript\n",
    "    test_data = {\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'tracks': [\n",
    "            {'id': 1, 'name': 'Kick Drum', 'volume': 0.8, 'muted': False},\n",
    "            {'id': 2, 'name': 'Bass Synth', 'volume': 0.7, 'muted': False},\n",
    "            {'id': 3, 'name': 'Lead Vocal', 'volume': 0.9, 'muted': False}\n",
    "        ],\n",
    "        'master_volume': 0.85,\n",
    "        'sample_rate': 44100,\n",
    "        'project_length': 30.0\n",
    "    }\n",
    "    \n",
    "    print(\"‚úÖ Test 1: Data Structure Creation\")\n",
    "    print(f\"   Generated project data with {len(test_data['tracks'])} tracks\")\n",
    "    \n",
    "    # Test 2: JSON serialization (for web component communication)\n",
    "    try:\n",
    "        json_data = json.dumps(test_data, indent=2)\n",
    "        print(\"‚úÖ Test 2: JSON Serialization\")\n",
    "        print(\"   Data successfully serialized for web component communication\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Test 2: JSON Serialization Failed - {e}\")\n",
    "    \n",
    "    # Test 3: File system operations\n",
    "    try:\n",
    "        demo_path = Path(\"demo_session.json\")\n",
    "        with open(demo_path, 'w') as f:\n",
    "            json.dump(test_data, f, indent=2)\n",
    "        print(\"‚úÖ Test 3: File System Write\")\n",
    "        print(f\"   Session data written to {demo_path}\")\n",
    "        \n",
    "        # Clean up\n",
    "        demo_path.unlink()\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Test 3: File System Write Failed - {e}\")\n",
    "    \n",
    "    # Test 4: Audio processing integration\n",
    "    if platform_caps.get('audio_processing', False):\n",
    "        try:\n",
    "            # Create a simple audio buffer\n",
    "            audio_buffer = np.random.random(1024) * 0.1\n",
    "            print(\"‚úÖ Test 4: Audio Buffer Creation\")\n",
    "            print(f\"   Created audio buffer with {len(audio_buffer)} samples\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Test 4: Audio Buffer Creation Failed - {e}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  Test 4: Audio Processing Skipped (libraries not available)\")\n",
    "    \n",
    "    # Test 5: Web component state management\n",
    "    component_state = {\n",
    "        'transport': {\n",
    "            'playing': False,\n",
    "            'position': 0.0,\n",
    "            'loop_enabled': True,\n",
    "            'tempo': 120\n",
    "        },\n",
    "        'mixer': {\n",
    "            'channels': [\n",
    "                {'volume': 0.8, 'pan': 0.0, 'mute': False, 'solo': False},\n",
    "                {'volume': 0.7, 'pan': -0.2, 'mute': False, 'solo': False},\n",
    "                {'volume': 0.9, 'pan': 0.1, 'mute': False, 'solo': False}\n",
    "            ],\n",
    "            'master': {'volume': 0.85, 'mute': False}\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(\"‚úÖ Test 5: Component State Management\")\n",
    "    print(f\"   Created state for {len(component_state)} component groups\")\n",
    "    \n",
    "    print(\"\\nüéØ Integration Test Summary:\")\n",
    "    print(\"   ‚úÖ Python Backend: Ready\")\n",
    "    print(\"   ‚úÖ Web Components: Ready\")\n",
    "    print(\"   ‚úÖ Data Exchange: Working\")\n",
    "    print(\"   ‚úÖ State Management: Working\")\n",
    "    print(f\"   {'‚úÖ' if platform_caps.get('audio_processing') else '‚ö†Ô∏è '} Audio Processing: {'Ready' if platform_caps.get('audio_processing') else 'Limited'}\")\n",
    "    \n",
    "    return {\n",
    "        'status': 'success',\n",
    "        'capabilities': platform_caps,\n",
    "        'test_data': test_data,\n",
    "        'component_state': component_state\n",
    "    }\n",
    "\n",
    "# Run integration tests\n",
    "integration_results = test_platform_integration()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b22730",
   "metadata": {},
   "source": [
    "## üöÄ Export and Sharing\n",
    "\n",
    "Export your demo session and component configurations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868dfcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export demo configuration and results\n",
    "def export_demo_session():\n",
    "    \"\"\"Export the complete demo session for sharing or further development\"\"\"\n",
    "    \n",
    "    export_data = {\n",
    "        'session_info': {\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'platform': 'Jupyter Notebook',\n",
    "            'environment': 'Python Backend',\n",
    "            'capabilities': platform_caps\n",
    "        },\n",
    "        'components_tested': [\n",
    "            'Transport Controls',\n",
    "            'Timeline Interface', \n",
    "            'Mixer Panel',\n",
    "            'Audio Processing',\n",
    "            'Platform Integration'\n",
    "        ],\n",
    "        'audio_generated': bool(audio_data) if 'audio_data' in globals() else False,\n",
    "        'integration_results': integration_results,\n",
    "        'recommendations': []\n",
    "    }\n",
    "    \n",
    "    # Add recommendations based on capabilities\n",
    "    if not platform_caps.get('audio_processing'):\n",
    "        export_data['recommendations'].append('Install audio processing libraries: pip install librosa soundfile')\n",
    "    \n",
    "    if platform_caps.get('machine_learning'):\n",
    "        export_data['recommendations'].append('Consider adding ML-based audio analysis features')\n",
    "    \n",
    "    if platform_caps.get('web_components'):\n",
    "        export_data['recommendations'].append('Web components ready for advanced interactive features')\n",
    "    \n",
    "    # Save to file\n",
    "    export_path = Path(\"orpheus_demo_session.json\")\n",
    "    with open(export_path, 'w') as f:\n",
    "        json.dump(export_data, f, indent=2)\n",
    "    \n",
    "    print(\"üìÑ Demo Session Export Complete\")\n",
    "    print(f\"üìÅ Saved to: {export_path}\")\n",
    "    print(f\"üìä Session includes {len(export_data['components_tested'])} tested components\")\n",
    "    print(f\"üí° {len(export_data['recommendations'])} recommendations generated\")\n",
    "    \n",
    "    # Display summary\n",
    "    display(HTML(f\"\"\"\n",
    "    <div style=\"background: #2c3e50; color: white; padding: 20px; border-radius: 8px; margin: 10px 0;\">\n",
    "        <h3 style=\"color: #3498db;\">üìã Demo Session Summary</h3>\n",
    "        <div style=\"display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 15px;\">\n",
    "            <div>\n",
    "                <strong>Environment:</strong><br>\n",
    "                {export_data['session_info']['platform']}<br>\n",
    "                {export_data['session_info']['environment']}\n",
    "            </div>\n",
    "            <div>\n",
    "                <strong>Components Tested:</strong><br>\n",
    "                {len(export_data['components_tested'])} components\n",
    "            </div>\n",
    "            <div>\n",
    "                <strong>Capabilities:</strong><br>\n",
    "                {sum(export_data['session_info']['capabilities'].values())} / {len(export_data['session_info']['capabilities'])} available\n",
    "            </div>\n",
    "            <div>\n",
    "                <strong>Audio Generated:</strong><br>\n",
    "                {'Yes' if export_data['audio_generated'] else 'No'}\n",
    "            </div>\n",
    "        </div>\n",
    "        <div style=\"margin-top: 15px;\">\n",
    "            <strong>Next Steps:</strong>\n",
    "            <ul>\n",
    "                {''.join(f'<li>{rec}</li>' for rec in export_data['recommendations']) if export_data['recommendations'] else '<li>All capabilities available - ready for production!</li>'}\n",
    "            </ul>\n",
    "        </div>\n",
    "    </div>\n",
    "    \"\"\"))\n",
    "    \n",
    "    return export_data\n",
    "\n",
    "# Export the session\n",
    "session_export = export_demo_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126b3dbd",
   "metadata": {},
   "source": [
    "## üéØ Next Steps\n",
    "\n",
    "This demo showcases the Orpheus Engine's cross-platform capabilities. Here's what you can do next:\n",
    "\n",
    "### üîß Development\n",
    "- **Integrate with Electron**: Use the same components in the desktop application\n",
    "- **Add Real Audio**: Connect with professional audio interfaces\n",
    "- **Extend Components**: Add more DAW features like effects, synthesis, and recording\n",
    "\n",
    "### üöÄ Deployment\n",
    "- **Web Version**: Deploy components as web applications\n",
    "- **Desktop App**: Package with Electron for native desktop experience  \n",
    "- **Backend Integration**: Connect with Python audio processing backend\n",
    "\n",
    "### üìö Documentation\n",
    "- **API Reference**: Document component interfaces and capabilities\n",
    "- **User Guide**: Create tutorials for different user types\n",
    "- **Developer Guide**: Setup instructions for contributors\n",
    "\n",
    "The demo files are saved in your working directory and can be imported into other projects or shared with team members."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
