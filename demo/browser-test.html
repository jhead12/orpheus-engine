<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Orpheus Engine - Browser Capabilities Test</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 40px;
            background-color: #1a1a1a;
            color: #ffffff;
        }
        .container {
            max-width: 800px;
            margin: 0 auto;
        }
        .test-result {
            margin: 10px 0;
            padding: 10px;
            border-radius: 5px;
            background-color: #2a2a2a;
        }
        .success { color: #4CAF50; }
        .error { color: #f44336; }
        pre {
            background-color: #333;
            padding: 15px;
            border-radius: 5px;
            overflow-x: auto;
        }
        #audioTest {
            margin-top: 20px;
            padding: 20px;
            border: 1px solid #444;
            border-radius: 5px;
        }
        button {
            background-color: #4CAF50;
            color: white;
            padding: 10px 20px;
            border: none;
            border-radius: 5px;
            cursor: pointer;
            margin: 5px;
        }
        button:hover {
            background-color: #45a049;
        }
        #waveform {
            width: 100%;
            height: 200px;
            background-color: #000;
            border: 1px solid #444;
            margin-top: 10px;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Orpheus Engine - Browser Capabilities Test</h1>
        <p>Testing browser support for audio analysis and visualization</p>
        
        <div id="results"></div>
        
        <div id="audioTest">
            <h3>Audio Analysis Test</h3>
            <p>Upload an audio file to test analysis capabilities:</p>
            <input type="file" id="audioFile" accept="audio/*">
            <button onclick="analyzeAudio()">Analyze Audio</button>
            <div id="audioResults"></div>
            <canvas id="waveform"></canvas>
        </div>
    </div>

    <script>
        // Test browser capabilities
        function testCapabilities() {
            const results = [];
            
            // Test AudioContext support
            try {
                const AudioContextClass = window.AudioContext || window.webkitAudioContext;
                if (AudioContextClass) {
                    const audioContext = new AudioContextClass();
                    results.push({
                        test: 'AudioContext Support',
                        status: 'success',
                        details: `Sample rate: ${audioContext.sampleRate}, State: ${audioContext.state}`
                    });
                    audioContext.close();
                } else {
                    results.push({
                        test: 'AudioContext Support',
                        status: 'error',
                        details: 'AudioContext not available'
                    });
                }
            } catch (error) {
                results.push({
                    test: 'AudioContext Support',
                    status: 'error',
                    details: error.message
                });
            }

            // Test File API support
            if (window.File && window.FileReader && window.FileList && window.Blob) {
                results.push({
                    test: 'File API Support',
                    status: 'success',
                    details: 'File, FileReader, FileList, and Blob APIs are available'
                });
            } else {
                results.push({
                    test: 'File API Support',
                    status: 'error',
                    details: 'One or more File APIs are missing'
                });
            }

            // Test Fetch API support
            if (window.fetch) {
                results.push({
                    test: 'Fetch API Support',
                    status: 'success',
                    details: 'Fetch API is available'
                });
            } else {
                results.push({
                    test: 'Fetch API Support',
                    status: 'error',
                    details: 'Fetch API not available'
                });
            }

            // Test Canvas support
            const canvas = document.createElement('canvas');
            if (canvas.getContext && canvas.getContext('2d')) {
                results.push({
                    test: 'Canvas 2D Support',
                    status: 'success',
                    details: 'Canvas 2D context is available'
                });
            } else {
                results.push({
                    test: 'Canvas 2D Support',
                    status: 'error',
                    details: 'Canvas 2D context not available'
                });
            }

            displayResults(results);
        }

        function displayResults(results) {
            const container = document.getElementById('results');
            results.forEach(result => {
                const div = document.createElement('div');
                div.className = `test-result ${result.status}`;
                div.innerHTML = `
                    <strong>${result.test}:</strong> 
                    <span class="${result.status}">${result.status === 'success' ? '✓' : '✗'}</span>
                    <br><small>${result.details}</small>
                `;
                container.appendChild(div);
            });
        }

        // Audio analysis function
        async function analyzeAudio() {
            const fileInput = document.getElementById('audioFile');
            const file = fileInput.files[0];
            
            if (!file) {
                alert('Please select an audio file first');
                return;
            }

            const results = document.getElementById('audioResults');
            results.innerHTML = '<p>Analyzing audio...</p>';

            try {
                const AudioContextClass = window.AudioContext || window.webkitAudioContext;
                const audioContext = new AudioContextClass();
                
                // Read file as array buffer
                const arrayBuffer = await file.arrayBuffer();
                
                // Decode audio data
                const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
                
                // Get audio data for analysis
                const channelData = audioBuffer.getChannelData(0);
                
                // Generate simple waveform
                drawWaveform(channelData);
                
                // Display results
                results.innerHTML = `
                    <div class="test-result success">
                        <strong>Audio Analysis Results:</strong><br>
                        <small>
                            Duration: ${audioBuffer.duration.toFixed(2)} seconds<br>
                            Sample Rate: ${audioBuffer.sampleRate} Hz<br>
                            Channels: ${audioBuffer.numberOfChannels}<br>
                            Length: ${audioBuffer.length} samples
                        </small>
                    </div>
                `;
                
                audioContext.close();
            } catch (error) {
                results.innerHTML = `
                    <div class="test-result error">
                        <strong>Audio Analysis Error:</strong><br>
                        <small>${error.message}</small>
                    </div>
                `;
            }
        }

        function drawWaveform(audioData) {
            const canvas = document.getElementById('waveform');
            const ctx = canvas.getContext('2d');
            
            canvas.width = canvas.offsetWidth;
            canvas.height = canvas.offsetHeight;
            
            ctx.fillStyle = '#000';
            ctx.fillRect(0, 0, canvas.width, canvas.height);
            
            ctx.strokeStyle = '#4CAF50';
            ctx.lineWidth = 1;
            ctx.beginPath();
            
            const sliceWidth = canvas.width / audioData.length;
            let x = 0;
            
            for (let i = 0; i < audioData.length; i++) {
                const v = audioData[i] * 0.5;
                const y = (v + 1) * canvas.height / 2;
                
                if (i === 0) {
                    ctx.moveTo(x, y);
                } else {
                    ctx.lineTo(x, y);
                }
                
                x += sliceWidth;
            }
            
            ctx.stroke();
        }

        // Run tests when page loads
        window.onload = testCapabilities;
    </script>
</body>
</html>
