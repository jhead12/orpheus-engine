{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agentic Retrieval-Augmented Generation (RAG) with Local Llama 2 & ChromaDB\n",
    "\n",
    "## Overview\n",
    "This notebook implements an **Agentic Retrieval-Augmented Generation (RAG) pipeline**. It focuses on transcribing audio data, potentially from an Omi streaming device, storing both the transcription and audio, and then using the transcription with a local **Ai Studio** model and **ChromaDB** for intelligent question-answering. The system determines whether additional context is needed before generating responses.\n",
    "\n",
    "### Key Features:\n",
    "- **Audio Transcription Workflow** for processing data from devices like Omi.\n",
    "- **Storage of Audio and Transcriptions** for AI processing.\n",
    "- **Llama 2 Model** for high-quality text generation.\n",
    "- **ChromaDB Vector Store** for efficient semantic search on transcriptions.\n",
    "- **Dynamic Context Retrieval** to improve answer accuracy.\n",
    "- **Two Answering Modes**:\n",
    "  - With RAG (Retrieves relevant document content before responding).\n",
    "  - Without RAG (Directly generates responses)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pypdf==5.3.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from -r requirements.txt (line 3)) (5.3.0)\n",
      "Requirement already satisfied: torch in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 4)) (2.6.0+cpu)\n",
      "Requirement already satisfied: huggingface-hub in /home/codespace/.python/current/lib/python3.12/site-packages (from -r requirements.txt (line 5)) (0.31.4)\n",
      "Requirement already satisfied: langchain_community in /home/codespace/.python/current/lib/python3.12/site-packages (from -r requirements.txt (line 6)) (0.3.24)\n",
      "Requirement already satisfied: sentence_transformers in /home/codespace/.python/current/lib/python3.12/site-packages (from -r requirements.txt (line 7)) (4.1.0)\n",
      "Requirement already satisfied: chromadb in /home/codespace/.python/current/lib/python3.12/site-packages (from -r requirements.txt (line 8)) (1.0.9)\n",
      "Requirement already satisfied: Plotly in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 9)) (6.0.1)\n",
      "Requirement already satisfied: scikit-image in /home/codespace/.python/current/lib/python3.12/site-packages (from -r requirements.txt (line 10)) (0.25.2)\n",
      "Requirement already satisfied: Seaborn in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 11)) (0.13.2)\n",
      "Requirement already satisfied: Altair in /home/codespace/.python/current/lib/python3.12/site-packages (from -r requirements.txt (line 12)) (5.5.0)\n",
      "Requirement already satisfied: Bokeh in /home/codespace/.python/current/lib/python3.12/site-packages (from -r requirements.txt (line 13)) (3.7.3)\n",
      "Requirement already satisfied: Bottleneck in /home/codespace/.python/current/lib/python3.12/site-packages (from -r requirements.txt (line 14)) (1.5.0)\n",
      "Requirement already satisfied: Bill in /home/codespace/.python/current/lib/python3.12/site-packages (from -r requirements.txt (line 15)) (0.0.1)\n",
      "Requirement already satisfied: h5py in /home/codespace/.python/current/lib/python3.12/site-packages (from -r requirements.txt (line 16)) (3.13.0)\n",
      "Requirement already satisfied: Ipympl in /home/codespace/.python/current/lib/python3.12/site-packages (from -r requirements.txt (line 17)) (0.9.7)\n",
      "Requirement already satisfied: Numba in /home/codespace/.python/current/lib/python3.12/site-packages (from -r requirements.txt (line 18)) (0.61.2)\n",
      "Requirement already satisfied: Statsmodels in /home/codespace/.python/current/lib/python3.12/site-packages (from -r requirements.txt (line 19)) (0.14.4)\n",
      "Requirement already satisfied: mlflow in /home/codespace/.python/current/lib/python3.12/site-packages (from -r requirements.txt (line 20)) (2.22.0)\n",
      "Requirement already satisfied: llama-cpp-python in /home/codespace/.python/current/lib/python3.12/site-packages (from -r requirements.txt (line 21)) (0.3.9)\n",
      "Requirement already satisfied: librosa in /home/codespace/.python/current/lib/python3.12/site-packages (from -r requirements.txt (line 22)) (0.11.0)\n",
      "Requirement already satisfied: espeakng in /home/codespace/.python/current/lib/python3.12/site-packages (from -r requirements.txt (line 23)) (1.0.3)\n",
      "Requirement already satisfied: openai-whisper in /home/codespace/.python/current/lib/python3.12/site-packages (from -r requirements.txt (line 26)) (20240930)\n",
      "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.12/site-packages (from torch->-r requirements.txt (line 4)) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/codespace/.local/lib/python3.12/site-packages (from torch->-r requirements.txt (line 4)) (4.12.2)\n",
      "Requirement already satisfied: networkx in /home/codespace/.local/lib/python3.12/site-packages (from torch->-r requirements.txt (line 4)) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.12/site-packages (from torch->-r requirements.txt (line 4)) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/codespace/.local/lib/python3.12/site-packages (from torch->-r requirements.txt (line 4)) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in /home/codespace/.local/lib/python3.12/site-packages (from torch->-r requirements.txt (line 4)) (76.0.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/codespace/.local/lib/python3.12/site-packages (from torch->-r requirements.txt (line 4)) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from sympy==1.13.1->torch->-r requirements.txt (line 4)) (1.3.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub->-r requirements.txt (line 5)) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub->-r requirements.txt (line 5)) (6.0.2)\n",
      "Requirement already satisfied: requests in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub->-r requirements.txt (line 5)) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/codespace/.python/current/lib/python3.12/site-packages (from huggingface-hub->-r requirements.txt (line 5)) (4.67.1)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.59 in /home/codespace/.python/current/lib/python3.12/site-packages (from langchain_community->-r requirements.txt (line 6)) (0.3.60)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.25 in /home/codespace/.python/current/lib/python3.12/site-packages (from langchain_community->-r requirements.txt (line 6)) (0.3.25)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/codespace/.python/current/lib/python3.12/site-packages (from langchain_community->-r requirements.txt (line 6)) (2.0.41)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/codespace/.python/current/lib/python3.12/site-packages (from langchain_community->-r requirements.txt (line 6)) (3.11.18)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from langchain_community->-r requirements.txt (line 6)) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /home/codespace/.python/current/lib/python3.12/site-packages (from langchain_community->-r requirements.txt (line 6)) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from langchain_community->-r requirements.txt (line 6)) (2.9.1)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /home/codespace/.python/current/lib/python3.12/site-packages (from langchain_community->-r requirements.txt (line 6)) (0.3.42)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from langchain_community->-r requirements.txt (line 6)) (0.4.0)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /home/codespace/.local/lib/python3.12/site-packages (from langchain_community->-r requirements.txt (line 6)) (2.2.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community->-r requirements.txt (line 6)) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/codespace/.python/current/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community->-r requirements.txt (line 6)) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/codespace/.local/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community->-r requirements.txt (line 6)) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/codespace/.python/current/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community->-r requirements.txt (line 6)) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/codespace/.python/current/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community->-r requirements.txt (line 6)) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community->-r requirements.txt (line 6)) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community->-r requirements.txt (line 6)) (1.20.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community->-r requirements.txt (line 6)) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community->-r requirements.txt (line 6)) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /home/codespace/.python/current/lib/python3.12/site-packages (from langchain<1.0.0,>=0.3.25->langchain_community->-r requirements.txt (line 6)) (0.3.8)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /home/codespace/.python/current/lib/python3.12/site-packages (from langchain<1.0.0,>=0.3.25->langchain_community->-r requirements.txt (line 6)) (2.11.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/codespace/.python/current/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.59->langchain_community->-r requirements.txt (line 6)) (1.33)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/codespace/.local/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.59->langchain_community->-r requirements.txt (line 6)) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/codespace/.local/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain_community->-r requirements.txt (line 6)) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/codespace/.python/current/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain_community->-r requirements.txt (line 6)) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain_community->-r requirements.txt (line 6)) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain_community->-r requirements.txt (line 6)) (0.23.0)\n",
      "Requirement already satisfied: anyio in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community->-r requirements.txt (line 6)) (4.9.0)\n",
      "Requirement already satisfied: certifi in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community->-r requirements.txt (line 6)) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community->-r requirements.txt (line 6)) (1.0.7)\n",
      "Requirement already satisfied: idna in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community->-r requirements.txt (line 6)) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/codespace/.local/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community->-r requirements.txt (line 6)) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain_community->-r requirements.txt (line 6)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/codespace/.python/current/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain_community->-r requirements.txt (line 6)) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain_community->-r requirements.txt (line 6)) (0.4.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community->-r requirements.txt (line 6)) (1.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests->huggingface-hub->-r requirements.txt (line 5)) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests->huggingface-hub->-r requirements.txt (line 5)) (2.3.0)\n",
      "Requirement already satisfied: greenlet>=1 in /home/codespace/.python/current/lib/python3.12/site-packages (from SQLAlchemy<3,>=1.4->langchain_community->-r requirements.txt (line 6)) (3.2.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community->-r requirements.txt (line 6)) (1.1.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from sentence_transformers->-r requirements.txt (line 7)) (4.52.2)\n",
      "Requirement already satisfied: scikit-learn in /home/codespace/.local/lib/python3.12/site-packages (from sentence_transformers->-r requirements.txt (line 7)) (1.6.1)\n",
      "Requirement already satisfied: scipy in /home/codespace/.local/lib/python3.12/site-packages (from sentence_transformers->-r requirements.txt (line 7)) (1.15.2)\n",
      "Requirement already satisfied: Pillow in /home/codespace/.local/lib/python3.12/site-packages (from sentence_transformers->-r requirements.txt (line 7)) (11.1.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/codespace/.python/current/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers->-r requirements.txt (line 7)) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/codespace/.python/current/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers->-r requirements.txt (line 7)) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/codespace/.python/current/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers->-r requirements.txt (line 7)) (0.5.3)\n",
      "Requirement already satisfied: build>=1.0.3 in /home/codespace/.python/current/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 8)) (1.2.2.post1)\n",
      "Requirement already satisfied: fastapi==0.115.9 in /home/codespace/.python/current/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 8)) (0.115.9)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /home/codespace/.python/current/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 8)) (0.34.2)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 8)) (4.0.1)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /home/codespace/.python/current/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 8)) (1.22.0)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 8)) (1.33.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 8)) (1.33.1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /home/codespace/.python/current/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 8)) (0.54b1)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 8)) (1.33.1)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /home/codespace/.python/current/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 8)) (0.48.9)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /home/codespace/.local/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 8)) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in /home/codespace/.python/current/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 8)) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 8)) (1.71.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /home/codespace/.python/current/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 8)) (4.3.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 8)) (0.15.4)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 8)) (32.0.1)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /home/codespace/.python/current/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 8)) (5.1.0)\n",
      "Requirement already satisfied: rich>=10.11.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 8)) (14.0.0)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in /home/codespace/.local/lib/python3.12/site-packages (from chromadb->-r requirements.txt (line 8)) (4.23.0)\n",
      "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from fastapi==0.115.9->chromadb->-r requirements.txt (line 8)) (0.45.3)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/codespace/.local/lib/python3.12/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community->-r requirements.txt (line 6)) (1.3.1)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in /home/codespace/.local/lib/python3.12/site-packages (from Plotly->-r requirements.txt (line 9)) (1.31.0)\n",
      "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /home/codespace/.python/current/lib/python3.12/site-packages (from scikit-image->-r requirements.txt (line 10)) (2.37.0)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /home/codespace/.python/current/lib/python3.12/site-packages (from scikit-image->-r requirements.txt (line 10)) (2025.5.10)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /home/codespace/.python/current/lib/python3.12/site-packages (from scikit-image->-r requirements.txt (line 10)) (0.4)\n",
      "Requirement already satisfied: pandas>=1.2 in /home/codespace/.local/lib/python3.12/site-packages (from Seaborn->-r requirements.txt (line 11)) (2.2.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /home/codespace/.local/lib/python3.12/site-packages (from Seaborn->-r requirements.txt (line 11)) (3.10.1)\n",
      "Requirement already satisfied: contourpy>=1.2 in /home/codespace/.local/lib/python3.12/site-packages (from Bokeh->-r requirements.txt (line 13)) (1.3.1)\n",
      "Requirement already satisfied: tornado>=6.2 in /home/codespace/.local/lib/python3.12/site-packages (from Bokeh->-r requirements.txt (line 13)) (6.4.2)\n",
      "Requirement already satisfied: xyzservices>=2021.09.1 in /home/codespace/.python/current/lib/python3.12/site-packages (from Bokeh->-r requirements.txt (line 13)) (2025.4.0)\n",
      "Requirement already satisfied: ipython<10 in /home/codespace/.local/lib/python3.12/site-packages (from Ipympl->-r requirements.txt (line 17)) (9.0.2)\n",
      "Requirement already satisfied: ipywidgets<9,>=7.6.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from Ipympl->-r requirements.txt (line 17)) (8.1.7)\n",
      "Requirement already satisfied: traitlets<6 in /home/codespace/.local/lib/python3.12/site-packages (from Ipympl->-r requirements.txt (line 17)) (5.14.3)\n",
      "Requirement already satisfied: decorator in /home/codespace/.local/lib/python3.12/site-packages (from ipython<10->Ipympl->-r requirements.txt (line 17)) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in /home/codespace/.local/lib/python3.12/site-packages (from ipython<10->Ipympl->-r requirements.txt (line 17)) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/codespace/.local/lib/python3.12/site-packages (from ipython<10->Ipympl->-r requirements.txt (line 17)) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /home/codespace/.local/lib/python3.12/site-packages (from ipython<10->Ipympl->-r requirements.txt (line 17)) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/codespace/.local/lib/python3.12/site-packages (from ipython<10->Ipympl->-r requirements.txt (line 17)) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /home/codespace/.local/lib/python3.12/site-packages (from ipython<10->Ipympl->-r requirements.txt (line 17)) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/codespace/.local/lib/python3.12/site-packages (from ipython<10->Ipympl->-r requirements.txt (line 17)) (2.19.1)\n",
      "Requirement already satisfied: stack_data in /home/codespace/.local/lib/python3.12/site-packages (from ipython<10->Ipympl->-r requirements.txt (line 17)) (0.6.3)\n",
      "Requirement already satisfied: comm>=0.1.3 in /home/codespace/.local/lib/python3.12/site-packages (from ipywidgets<9,>=7.6.0->Ipympl->-r requirements.txt (line 17)) (0.2.2)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in /home/codespace/.python/current/lib/python3.12/site-packages (from ipywidgets<9,>=7.6.0->Ipympl->-r requirements.txt (line 17)) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /home/codespace/.python/current/lib/python3.12/site-packages (from ipywidgets<9,>=7.6.0->Ipympl->-r requirements.txt (line 17)) (3.0.15)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->Seaborn->-r requirements.txt (line 11)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->Seaborn->-r requirements.txt (line 11)) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->Seaborn->-r requirements.txt (line 11)) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->Seaborn->-r requirements.txt (line 11)) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->Seaborn->-r requirements.txt (line 11)) (2.9.0.post0)\n",
      "Requirement already satisfied: wcwidth in /home/codespace/.local/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython<10->Ipympl->-r requirements.txt (line 17)) (0.2.13)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /home/codespace/.python/current/lib/python3.12/site-packages (from Numba->-r requirements.txt (line 18)) (0.44.0)\n",
      "Requirement already satisfied: patsy>=0.5.6 in /home/codespace/.python/current/lib/python3.12/site-packages (from Statsmodels->-r requirements.txt (line 19)) (1.0.1)\n",
      "Requirement already satisfied: mlflow-skinny==2.22.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from mlflow->-r requirements.txt (line 20)) (2.22.0)\n",
      "Requirement already satisfied: Flask<4 in /home/codespace/.python/current/lib/python3.12/site-packages (from mlflow->-r requirements.txt (line 20)) (3.1.1)\n",
      "Requirement already satisfied: alembic!=1.10.0,<2 in /home/codespace/.python/current/lib/python3.12/site-packages (from mlflow->-r requirements.txt (line 20)) (1.16.1)\n",
      "Requirement already satisfied: docker<8,>=4.0.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from mlflow->-r requirements.txt (line 20)) (7.1.0)\n",
      "Requirement already satisfied: graphene<4 in /home/codespace/.python/current/lib/python3.12/site-packages (from mlflow->-r requirements.txt (line 20)) (3.4.3)\n",
      "Requirement already satisfied: gunicorn<24 in /home/codespace/.python/current/lib/python3.12/site-packages (from mlflow->-r requirements.txt (line 20)) (23.0.0)\n",
      "Requirement already satisfied: markdown<4,>=3.3 in /home/codespace/.python/current/lib/python3.12/site-packages (from mlflow->-r requirements.txt (line 20)) (3.8)\n",
      "Requirement already satisfied: pyarrow<20,>=4.0.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from mlflow->-r requirements.txt (line 20)) (19.0.1)\n",
      "Requirement already satisfied: cachetools<6,>=5.0.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from mlflow-skinny==2.22.0->mlflow->-r requirements.txt (line 20)) (5.5.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from mlflow-skinny==2.22.0->mlflow->-r requirements.txt (line 20)) (8.1.8)\n",
      "Requirement already satisfied: cloudpickle<4 in /home/codespace/.python/current/lib/python3.12/site-packages (from mlflow-skinny==2.22.0->mlflow->-r requirements.txt (line 20)) (3.1.1)\n",
      "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from mlflow-skinny==2.22.0->mlflow->-r requirements.txt (line 20)) (0.53.0)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in /home/codespace/.local/lib/python3.12/site-packages (from mlflow-skinny==2.22.0->mlflow->-r requirements.txt (line 20)) (3.1.44)\n",
      "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from mlflow-skinny==2.22.0->mlflow->-r requirements.txt (line 20)) (8.6.1)\n",
      "Requirement already satisfied: protobuf<7,>=3.12.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from mlflow-skinny==2.22.0->mlflow->-r requirements.txt (line 20)) (5.29.4)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from mlflow-skinny==2.22.0->mlflow->-r requirements.txt (line 20)) (0.5.3)\n",
      "Requirement already satisfied: Mako in /home/codespace/.python/current/lib/python3.12/site-packages (from alembic!=1.10.0,<2->mlflow->-r requirements.txt (line 20)) (1.3.10)\n",
      "Requirement already satisfied: google-auth~=2.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow->-r requirements.txt (line 20)) (2.40.2)\n",
      "Requirement already satisfied: blinker>=1.9.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from Flask<4->mlflow->-r requirements.txt (line 20)) (1.9.0)\n",
      "Requirement already satisfied: itsdangerous>=2.2.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from Flask<4->mlflow->-r requirements.txt (line 20)) (2.2.0)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in /home/codespace/.local/lib/python3.12/site-packages (from Flask<4->mlflow->-r requirements.txt (line 20)) (3.0.2)\n",
      "Requirement already satisfied: werkzeug>=3.1.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from Flask<4->mlflow->-r requirements.txt (line 20)) (3.1.3)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/codespace/.local/lib/python3.12/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.22.0->mlflow->-r requirements.txt (line 20)) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/codespace/.local/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.22.0->mlflow->-r requirements.txt (line 20)) (5.0.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/codespace/.python/current/lib/python3.12/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow->-r requirements.txt (line 20)) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/codespace/.python/current/lib/python3.12/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow->-r requirements.txt (line 20)) (4.9.1)\n",
      "Requirement already satisfied: graphql-core<3.3,>=3.1 in /home/codespace/.python/current/lib/python3.12/site-packages (from graphene<4->mlflow->-r requirements.txt (line 20)) (3.2.6)\n",
      "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /home/codespace/.python/current/lib/python3.12/site-packages (from graphene<4->mlflow->-r requirements.txt (line 20)) (3.2.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /home/codespace/.python/current/lib/python3.12/site-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.22.0->mlflow->-r requirements.txt (line 20)) (3.21.0)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /home/codespace/.python/current/lib/python3.12/site-packages (from opentelemetry-api>=1.2.0->chromadb->-r requirements.txt (line 8)) (1.2.18)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.54b1 in /home/codespace/.python/current/lib/python3.12/site-packages (from opentelemetry-sdk>=1.2.0->chromadb->-r requirements.txt (line 8)) (0.54b1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.12/site-packages (from pandas>=1.2->Seaborn->-r requirements.txt (line 11)) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.12/site-packages (from pandas>=1.2->Seaborn->-r requirements.txt (line 11)) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->Seaborn->-r requirements.txt (line 11)) (1.17.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /home/codespace/.python/current/lib/python3.12/site-packages (from rsa<5,>=3.1.4->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow->-r requirements.txt (line 20)) (0.6.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/codespace/.local/lib/python3.12/site-packages (from scikit-learn->sentence_transformers->-r requirements.txt (line 7)) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from scikit-learn->sentence_transformers->-r requirements.txt (line 7)) (3.6.0)\n",
      "Requirement already satisfied: diskcache>=5.6.1 in /home/codespace/.python/current/lib/python3.12/site-packages (from llama-cpp-python->-r requirements.txt (line 21)) (5.6.3)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /home/codespace/.python/current/lib/python3.12/site-packages (from librosa->-r requirements.txt (line 22)) (3.0.1)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /home/codespace/.python/current/lib/python3.12/site-packages (from librosa->-r requirements.txt (line 22)) (0.13.1)\n",
      "Requirement already satisfied: pooch>=1.1 in /home/codespace/.python/current/lib/python3.12/site-packages (from librosa->-r requirements.txt (line 22)) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /home/codespace/.python/current/lib/python3.12/site-packages (from librosa->-r requirements.txt (line 22)) (0.5.0.post1)\n",
      "Requirement already satisfied: msgpack>=1.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from librosa->-r requirements.txt (line 22)) (1.1.0)\n",
      "Requirement already satisfied: more-itertools in /home/codespace/.python/current/lib/python3.12/site-packages (from openai-whisper->-r requirements.txt (line 26)) (10.7.0)\n",
      "Requirement already satisfied: tiktoken in /home/codespace/.python/current/lib/python3.12/site-packages (from openai-whisper->-r requirements.txt (line 26)) (0.9.0)\n",
      "Requirement already satisfied: triton>=2.0.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from openai-whisper->-r requirements.txt (line 26)) (3.3.0)\n",
      "Requirement already satisfied: pyproject_hooks in /home/codespace/.python/current/lib/python3.12/site-packages (from build>=1.0.3->chromadb->-r requirements.txt (line 8)) (1.2.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /home/codespace/.python/current/lib/python3.12/site-packages (from deprecated>=1.2.6->opentelemetry-api>=1.2.0->chromadb->-r requirements.txt (line 8)) (1.17.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /home/codespace/.local/lib/python3.12/site-packages (from jedi>=0.16->ipython<10->Ipympl->-r requirements.txt (line 17)) (0.8.4)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/codespace/.local/lib/python3.12/site-packages (from jsonschema>=4.19.0->chromadb->-r requirements.txt (line 8)) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/codespace/.local/lib/python3.12/site-packages (from jsonschema>=4.19.0->chromadb->-r requirements.txt (line 8)) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/codespace/.local/lib/python3.12/site-packages (from jsonschema>=4.19.0->chromadb->-r requirements.txt (line 8)) (0.23.1)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /home/codespace/.local/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 8)) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in /home/codespace/.python/current/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 8)) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /home/codespace/.python/current/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 8)) (3.2.2)\n",
      "Requirement already satisfied: durationpy>=0.7 in /home/codespace/.python/current/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 8)) (0.10)\n",
      "Requirement already satisfied: coloredlogs in /home/codespace/.python/current/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 8)) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /home/codespace/.python/current/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 8)) (25.2.10)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /home/codespace/.python/current/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 8)) (1.70.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.33.1 in /home/codespace/.python/current/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 8)) (1.33.1)\n",
      "Requirement already satisfied: opentelemetry-proto==1.33.1 in /home/codespace/.python/current/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 8)) (1.33.1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.54b1 in /home/codespace/.python/current/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 8)) (0.54b1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.54b1 in /home/codespace/.python/current/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 8)) (0.54b1)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.54b1 in /home/codespace/.python/current/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 8)) (0.54b1)\n",
      "Requirement already satisfied: asgiref~=3.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from opentelemetry-instrumentation-asgi==0.54b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 8)) (3.8.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/codespace/.local/lib/python3.12/site-packages (from pexpect>4.3->ipython<10->Ipympl->-r requirements.txt (line 17)) (0.7.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /home/codespace/.local/lib/python3.12/site-packages (from pooch>=1.1->librosa->-r requirements.txt (line 22)) (4.3.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from posthog>=2.4.0->chromadb->-r requirements.txt (line 8)) (2.2.1)\n",
      "Requirement already satisfied: distro>=1.5.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from posthog>=2.4.0->chromadb->-r requirements.txt (line 8)) (1.9.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from rich>=10.11.0->chromadb->-r requirements.txt (line 8)) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/codespace/.python/current/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb->-r requirements.txt (line 8)) (0.1.2)\n",
      "Requirement already satisfied: cffi>=1.0 in /home/codespace/.local/lib/python3.12/site-packages (from soundfile>=0.12.1->librosa->-r requirements.txt (line 22)) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /home/codespace/.local/lib/python3.12/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa->-r requirements.txt (line 22)) (2.22)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from typer>=0.9.0->chromadb->-r requirements.txt (line 8)) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /home/codespace/.python/current/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 8)) (0.6.4)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 8)) (0.21.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /home/codespace/.python/current/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 8)) (1.0.5)\n",
      "Requirement already satisfied: websockets>=10.4 in /home/codespace/.python/current/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 8)) (15.0.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/codespace/.python/current/lib/python3.12/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 8)) (10.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/codespace/.local/lib/python3.12/site-packages (from stack_data->ipython<10->Ipympl->-r requirements.txt (line 17)) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from stack_data->ipython<10->Ipympl->-r requirements.txt (line 17)) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /home/codespace/.local/lib/python3.12/site-packages (from stack_data->ipython<10->Ipympl->-r requirements.txt (line 17)) (0.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install required packages if you have not installed them already\n",
    "%pip install -r requirements.txt --verbose --quiet\n",
    "%pip install -q --upgrade pip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔧 Step 1: Model Setup\n",
    "\n",
    "We will set up **Llama 2 (7B)** for text generation. If the model is not found locally, it will be downloaded from Hugging Face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Model already exists at: model/llama-2-7b-chat.Q4_K_M.gguf\n",
      "Using model at: model/llama-2-7b-chat.Q4_K_M.gguf\n"
     ]
    }
   ],
   "source": [
    "%pip install -q huggingface-hub\n",
    "\n",
    "import os\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "MODEL_FILENAME = \"llama-2-7b-chat.Q4_K_M.gguf\"\n",
    "MODEL_DIR = \"model\"\n",
    "EXPECTED_PATH = os.path.join(MODEL_DIR, MODEL_FILENAME)\n",
    "\n",
    "# Ensure model directory exists\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "# Check if model already exists\n",
    "if os.path.exists(EXPECTED_PATH):\n",
    "    print(f\"Model already exists at: {EXPECTED_PATH}\")\n",
    "    model_path = EXPECTED_PATH\n",
    "else:\n",
    "    print(\"Model not found locally. Downloading Llama 2 model...\")\n",
    "    \n",
    "    # Download the model\n",
    "    model_path = hf_hub_download(\n",
    "        repo_id=\"TheBloke/Llama-2-7B-Chat-GGUF\",\n",
    "        filename=MODEL_FILENAME,\n",
    "        local_dir=MODEL_DIR\n",
    "    )\n",
    "    print(f\"Model downloaded to: {model_path}\")\n",
    "\n",
    "print(f\"Using model at: {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q llama-cpp-python\n",
    "# Check if the model file exists\n",
    "if not os.path.exists(model_path):\n",
    "    raise FileNotFoundError(f\"Model file not found at {model_path}\")\n",
    "\n",
    "# Import the Llama class from llama_cpp\n",
    "from llama_cpp import Llama\n",
    "\n",
    "# Initialize the model with the local path and GPU acceleration\n",
    "llm = Llama(\n",
    "    model_path=EXPECTED_PATH,\n",
    "    temperature=0.25,\n",
    "    max_tokens=2000,\n",
    "    n_ctx=4096,\n",
    "    top_p=1.0,\n",
    "    verbose=False,\n",
    "    n_gpu_layers=30,  # Utilize some available GPU layers\n",
    "    n_batch=512,      # Optimize batch size for parallel processing\n",
    "    f16_kv=True,      # Enable half-precision for key/value cache\n",
    "    use_mlock=True,   # Lock memory to prevent swapping\n",
    "    use_mmap=True     # Utilize memory mapping for faster loading\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📄 Step 2: Loading, Transcribing, and Storing Audio Data\n",
    "\n",
    "This step outlines the process for loading audio data (e.g., from an Omi streaming device), transcribing it, and preparing it for storage and further processing. Both the raw audio and its transcription are valuable assets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "ffmpeg found and working.\n",
      "Loading AUDIO from: ./data/tester.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.12/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 1 document(s) from the AUDIO.\n",
      "Successfully loaded 1 document(s) from the AUDIO and created 1 audio file(s).\n"
     ]
    }
   ],
   "source": [
    "# --- Load the Audio File Document ---\n",
    "# --- Load the Audio File Document and Audio Collection System ---\n",
    "\n",
    "# Install whisper if not already installed\n",
    "%pip install -q openai-whisper\n",
    "\n",
    "# Install ffmpeg-python bindings if not already installed\n",
    "%pip install -q ffmpeg-python\n",
    "\n",
    "import shutil\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# Check if ffmpeg is available and working\n",
    "try:\n",
    "    subprocess.run([\"ffmpeg\", \"-version\"], capture_output=True, check=True)\n",
    "    print(\"ffmpeg found and working.\")\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError(\"ffmpeg not found. Please install ffmpeg and ensure it's in your PATH.\")\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"Error running ffmpeg: {{e}}\")\n",
    "    raise RuntimeError(\"ffmpeg is not working correctly.\") from e\n",
    "\n",
    "import whisper\n",
    "\n",
    "# No need to manually set ffmpeg_dir if ffmpeg is installed system-wide\n",
    "\n",
    "# Define the Audio File file path\n",
    "AUDIO_PATH = \"./data/tester.mp3\"\n",
    "# Check if the file exists\n",
    "print(f\"Loading AUDIO from: {AUDIO_PATH}\")\n",
    "\n",
    "# Define the audio collection system\n",
    "AUDIO_COLLECTION_SYSTEM = \"MyAudioSystem\"\n",
    "\n",
    "# Load and transcribe the audio file using whisper\n",
    "model = whisper.load_model(\"base\")\n",
    "result = model.transcribe(AUDIO_PATH)\n",
    "text_content = result[\"text\"]\n",
    "\n",
    "# For compatibility with the rest of your code, wrap the text in a document-like object\n",
    "class AudioDocument:\n",
    "    def __init__(self, text):\n",
    "        self.text = text\n",
    "    def getPageText(self):\n",
    "        return self.text\n",
    "\n",
    "documents = [AudioDocument(text_content)]\n",
    "\n",
    "print(f\"Successfully loaded {len(documents)} document(s) from the AUDIO.\")\n",
    "# Initialize an empty list for the audio files\n",
    "audio_files = []\n",
    "\n",
    "# Iterate through each document\n",
    "for document in documents:\n",
    "    # Get the current page's text content\n",
    "    text_content = document.getPageText()\n",
    "\n",
    "    # Extract relevant information from the text, e.g., keywords or phrases\n",
    "    def extractRelevantInfo(text):\n",
    "        # Placeholder: just return the text itself\n",
    "        return text\n",
    "    extracted_info = extractRelevantInfo(text_content)\n",
    "\n",
    "    # Define a placeholder for createAudioFile\n",
    "    def createAudioFile(system, info):\n",
    "        # Placeholder: just return a tuple for demonstration\n",
    "        return (system, info)\n",
    "\n",
    "    # Create an audio file based on the extracted information\n",
    "    audio_file = createAudioFile(AUDIO_COLLECTION_SYSTEM, extracted_info)\n",
    "\n",
    "    # Add the audio file to the collection system's list\n",
    "    audio_files.append(audio_file)\n",
    "print(f\"Successfully loaded {len(documents)} document(s) from the AUDIO and created {len(audio_files)} audio file(s).\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 404: Not Found",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchaudio\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Download and load a pre-trained PANNs model for sound event detection\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m panns_model = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhub\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mqiuqiangkong/panns\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mCnn14\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpretrained\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m panns_model.eval()\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Load and preprocess audio\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/site-packages/torch/hub.py:638\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(repo_or_dir, model, source, trust_repo, force_reload, verbose, skip_validation, *args, **kwargs)\u001b[39m\n\u001b[32m    633\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    634\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mUnknown source: \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msource\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m. Allowed values: \u001b[39m\u001b[33m\"\u001b[39m\u001b[33mgithub\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m | \u001b[39m\u001b[33m\"\u001b[39m\u001b[33mlocal\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    635\u001b[39m     )\n\u001b[32m    637\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m source == \u001b[33m\"\u001b[39m\u001b[33mgithub\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m638\u001b[39m     repo_or_dir = \u001b[43m_get_cache_or_reload\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    639\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_or_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    640\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_reload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    641\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrust_repo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    642\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mload\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    643\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    644\u001b[39m \u001b[43m        \u001b[49m\u001b[43mskip_validation\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskip_validation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    645\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    647\u001b[39m model = _load_local(repo_or_dir, model, *args, **kwargs)\n\u001b[32m    648\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/site-packages/torch/hub.py:258\u001b[39m, in \u001b[36m_get_cache_or_reload\u001b[39m\u001b[34m(github, force_reload, trust_repo, calling_fn, verbose, skip_validation)\u001b[39m\n\u001b[32m    255\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    256\u001b[39m     \u001b[38;5;66;03m# Validate the tag/branch is from the original repo instead of a forked repo\u001b[39;00m\n\u001b[32m    257\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m skip_validation:\n\u001b[32m--> \u001b[39m\u001b[32m258\u001b[39m         \u001b[43m_validate_not_a_forked_repo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepo_owner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepo_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    260\u001b[39m     cached_file = os.path.join(hub_dir, normalized_br + \u001b[33m\"\u001b[39m\u001b[33m.zip\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    261\u001b[39m     _remove_if_exists(cached_file)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/site-packages/torch/hub.py:203\u001b[39m, in \u001b[36m_validate_not_a_forked_repo\u001b[39m\u001b[34m(repo_owner, repo_name, ref)\u001b[39m\n\u001b[32m    201\u001b[39m page += \u001b[32m1\u001b[39m\n\u001b[32m    202\u001b[39m url = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m?per_page=100&page=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpage\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m response = json.loads(\u001b[43m_read_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    204\u001b[39m \u001b[38;5;66;03m# Empty response means no more data to process\u001b[39;00m\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m response:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/site-packages/torch/hub.py:185\u001b[39m, in \u001b[36m_read_url\u001b[39m\u001b[34m(url)\u001b[39m\n\u001b[32m    184\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_url\u001b[39m(url):\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m r:\n\u001b[32m    186\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m r.read().decode(r.headers.get_content_charset(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/urllib/request.py:215\u001b[39m, in \u001b[36murlopen\u001b[39m\u001b[34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[39m\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    214\u001b[39m     opener = _opener\n\u001b[32m--> \u001b[39m\u001b[32m215\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/urllib/request.py:521\u001b[39m, in \u001b[36mOpenerDirector.open\u001b[39m\u001b[34m(self, fullurl, data, timeout)\u001b[39m\n\u001b[32m    519\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.process_response.get(protocol, []):\n\u001b[32m    520\u001b[39m     meth = \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[32m--> \u001b[39m\u001b[32m521\u001b[39m     response = \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    523\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/urllib/request.py:630\u001b[39m, in \u001b[36mHTTPErrorProcessor.http_response\u001b[39m\u001b[34m(self, request, response)\u001b[39m\n\u001b[32m    627\u001b[39m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[32m    628\u001b[39m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[32m    629\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[32m200\u001b[39m <= code < \u001b[32m300\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m630\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparent\u001b[49m\u001b[43m.\u001b[49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    631\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mhttp\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    633\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/urllib/request.py:559\u001b[39m, in \u001b[36mOpenerDirector.error\u001b[39m\u001b[34m(self, proto, *args)\u001b[39m\n\u001b[32m    557\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[32m    558\u001b[39m     args = (\u001b[38;5;28mdict\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mdefault\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mhttp_error_default\u001b[39m\u001b[33m'\u001b[39m) + orig_args\n\u001b[32m--> \u001b[39m\u001b[32m559\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/urllib/request.py:492\u001b[39m, in \u001b[36mOpenerDirector._call_chain\u001b[39m\u001b[34m(self, chain, kind, meth_name, *args)\u001b[39m\n\u001b[32m    490\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[32m    491\u001b[39m     func = \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[32m--> \u001b[39m\u001b[32m492\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    493\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    494\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/urllib/request.py:639\u001b[39m, in \u001b[36mHTTPDefaultErrorHandler.http_error_default\u001b[39m\u001b[34m(self, req, fp, code, msg, hdrs)\u001b[39m\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[32m--> \u001b[39m\u001b[32m639\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req.full_url, code, msg, hdrs, fp)\n",
      "\u001b[31mHTTPError\u001b[39m: HTTP Error 404: Not Found"
     ]
    }
   ],
   "source": [
    "# --- Audio Event Detection (Sound Tagging) ---\n",
    "\n",
    "%pip install -q torchaudio\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "# Download and load a pre-trained PANNs model for sound event detection\n",
    "panns_model = torch.hub.load('qiuqiangkong/panns', 'Cnn14', pretrained=True)\n",
    "panns_model.eval()\n",
    "\n",
    "# Load and preprocess audio\n",
    "waveform, sr = torchaudio.load(AUDIO_PATH)\n",
    "if sr != 32000:\n",
    "    waveform = torchaudio.transforms.Resample(orig_freq=sr, new_freq=32000)(waveform)\n",
    "    sr = 32000\n",
    "\n",
    "# PANNs expects mono audio\n",
    "if waveform.shape[0] > 1:\n",
    "    waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
    "\n",
    "# Run model and get tags\n",
    "with torch.no_grad():\n",
    "    output = panns_model(waveform)\n",
    "    # Get top 3 predicted sound classes\n",
    "    labels = panns_model.labels\n",
    "    topk = torch.topk(output['clipwise_output'][0], 3)\n",
    "    sound_tags = [labels[i] for i in topk.indices.tolist()]\n",
    "\n",
    "print(\"Detected sound types:\", sound_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ✂️ Step 3: Chunking Audio Transcriptions for RAG\n",
    "\n",
    "The transcribed text from the audio data is split into **small overlapping chunks** (approximately **500 characters**). These chunks are then used for embedding and storage in ChromaDB to enable semantic search for the RAG pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Split the Audio Content into Manageable Chunks with Sound Tags ---\n",
    "%pip install -q langchain\n",
    "\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "CHUNK_SIZE = 500\n",
    "CHUNK_OVERLAP = 50\n",
    "text_splitter = CharacterTextSplitter(chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP)\n",
    "\n",
    "# Split the transcription into chunks\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "# Attach sound tags to each chunk as metadata\n",
    "for doc in docs:\n",
    "    doc.page_content = f\"Transcription: {doc.page_content}\\nSound tags: {', '.join(sound_tags)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔍 Step 4: Initializing the Embedding Model\n",
    "\n",
    "To convert text into numerical representations for efficient similarity search, we use **all-MiniLM-L6-v2** from `sentence-transformers`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Initialize the Embedding Model ---\n",
    "%pip install -q sentence-transformers\n",
    "# Define the embedding model name\n",
    "MODEL_NAME = \"all-MiniLM-L6-v2\"\n",
    "\n",
    "# Load the embedding model\n",
    "embedding_model = SentenceTransformer(MODEL_NAME)\n",
    "\n",
    "print(f\"Successfully loaded embedding model: {MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🧠 Step 5: Computing Embeddings for Document Chunks\n",
    "\n",
    "Each chunk is converted into a **vector representation** using our embedding model. This allows us to perform **semantic similarity searches** later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Compute Embeddings for Each Text Chunk ---\n",
    "\n",
    "# Extract text content from each chunk\n",
    "doc_texts = [doc.page_content for doc in docs]\n",
    "\n",
    "# Compute embeddings for the extracted text chunks\n",
    "document_embeddings = embedding_model.encode(doc_texts, convert_to_numpy=True)\n",
    "\n",
    "# Display the result\n",
    "print(\"Successfully computed embeddings for each text chunk.\")\n",
    "print(f\"Embeddings Shape: {document_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🗄️ Step 6: Storing Audio Transcription Embeddings in ChromaDB\n",
    "\n",
    "We initialize **ChromaDB**, a high-performance **vector database**, and store our computed embeddings to enable efficient retrieval of relevant text chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Initialize and Populate the Chroma Vector Database ---\n",
    "\n",
    "# Define Chroma database path and collection name\n",
    "CHROMA_DB_PATH = \"./chroma_db\"\n",
    "COLLECTION_NAME = \"document_embeddings\"\n",
    "\n",
    "# Initialize Chroma client\n",
    "chroma_client = chromadb.PersistentClient(path=CHROMA_DB_PATH)\n",
    "collection = chroma_client.get_or_create_collection(name=COLLECTION_NAME)\n",
    "\n",
    "# Add document embeddings to the Chroma collection\n",
    "for i, embedding in enumerate(document_embeddings):\n",
    "    collection.add(\n",
    "        ids=[str(i)],  # Chroma requires string IDs\n",
    "        embeddings=[embedding.tolist()],\n",
    "        metadatas=[{\"text\": doc_texts[i]}]\n",
    "    )\n",
    "\n",
    "print(\"Successfully populated Chroma database with document embeddings.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔎 Step 7: Implementing Vector Search Tool\n",
    "\n",
    "To retrieve relevant text passages from the database, we define a **vector search function** that finds the most relevant chunks based on a user query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define the Vector Search Tool ---\n",
    "def vector_search_tool(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Searches the Chroma database for relevant text chunks based on the query.\n",
    "    Computes the query embedding, retrieves the top 5 most relevant text chunks,\n",
    "    and returns them as a formatted string.\n",
    "    \"\"\"\n",
    "    # Compute the query embedding\n",
    "    query_embedding = embedding_model.encode(query, convert_to_numpy=True).tolist()\n",
    "    \n",
    "    # Define the number of nearest neighbors to retrieve\n",
    "    TOP_K = 5\n",
    "    \n",
    "    # Perform the search in the Chroma database\n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_embedding],\n",
    "        n_results=TOP_K\n",
    "    )\n",
    "    \n",
    "    # Retrieve and format the corresponding text chunks\n",
    "    retrieved_chunks = [metadata[\"text\"] for metadata in results[\"metadatas\"][0]]\n",
    "    return \"\\n\\n\".join(retrieved_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🤖 Step 8: Context Need Assessment\n",
    "\n",
    "Instead of always retrieving context, we determine if the query **requires external document context** before generating a response. This creates an agentic workflow that makes autonomous decisions to complete the task at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define the Meta-Evaluation Function ---\n",
    "def needs_context(query: str) -> bool:\n",
    "    \"\"\"\n",
    "    Determines if additional context from an external document is required to generate an accurate and detailed answer.\n",
    "    Returns True if context is needed (response contains \"YES\"), False otherwise.\n",
    "\n",
    "    Args:\n",
    "        query (str): The user's query to evaluate.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if external context is required, False otherwise.\n",
    "    \"\"\"\n",
    "    meta_prompt = (\n",
    "        \"Based on the following query, decide if additional context from an external document is needed \"\n",
    "        \"to generate an accurate and detailed answer. Have a tendency to use an external document if the query is not a very familiar topic. If in doubt, assume context is required and answer 'YES'.\\n\"\n",
    "        \"Answer with a single word: YES if additional context from an external document would be helpful to answer the query, \"\n",
    "        \"or NO if not. Do not say anything other than YES or NO.\\n\"\n",
    "        f\"Query: {query}\\n\"\n",
    "        \"Answer:\"\n",
    "    )\n",
    "    meta_response = llm.invoke(meta_prompt)\n",
    "    print(\"Meta Response (is external document retrieval necessary?):\", meta_response)\n",
    "    return \"YES\" in meta_response.upper()\n",
    "\n",
    "\n",
    "# --- Define the Main Answer Generation Function with RAG (Retrieve and Generate) ---\n",
    "def generate_answer_with_agentic_rag(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Generates a detailed and accurate answer to the user's query by using context when needed.\n",
    "    If additional context is required, it is retrieved from the vector store and included in the prompt.\n",
    "    If not, the answer is generated using the query alone.\n",
    "\n",
    "    Args:\n",
    "        query (str): The user's query to answer.\n",
    "\n",
    "    Returns:\n",
    "        str: The generated answer based on the query.\n",
    "    \"\"\"\n",
    "    if needs_context(query):\n",
    "        # Retrieve additional context from the vector store\n",
    "        context = vector_search_tool(query)\n",
    "        \n",
    "        # Construct the enriched prompt with the additional context\n",
    "        enriched_prompt = (\n",
    "            \"Here is additional context from our document:\\n\"\n",
    "            f\"{context}\\n\\n\"\n",
    "            f\"Based on this context and the query: {query}\\n\"\n",
    "            \"Please provide a detailed and accurate answer.\\n\"\n",
    "            \"Answer:\"\n",
    "        )\n",
    "        final_response = llm.invoke(enriched_prompt)\n",
    "    else:\n",
    "        # Generate an answer using the original query directly\n",
    "        direct_prompt = (\n",
    "            \"Please provide a detailed and accurate answer to the following query:\\n\"\n",
    "            f\"{query}\\n\"\n",
    "            \"Answer:\"\n",
    "        )\n",
    "        final_response = llm.invoke(direct_prompt)\n",
    "    \n",
    "    return final_response\n",
    "\n",
    "\n",
    "# --- Define the Answer Generation Function without RAG ---\n",
    "def generate_answer_without_rag(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Generates a detailed and accurate answer to the user's query without using any additional context from external documents.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The user's query to answer.\n",
    "\n",
    "    Returns:\n",
    "        str: The generated answer based on the query.\n",
    "    \"\"\"\n",
    "    direct_prompt = (\n",
    "        \"Please provide a detailed and accurate answer to the following query:\\n\"\n",
    "        f\"{query}\\n\"\n",
    "        \"Answer:\"\n",
    "    )\n",
    "    final_response = llm.invoke(direct_prompt)\n",
    "    \n",
    "    return final_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 💡 Step 9: Answer Generation with Agentic RAG\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
